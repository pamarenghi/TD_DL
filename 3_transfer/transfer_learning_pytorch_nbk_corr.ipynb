{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apprentissage profond - TD n°3\n",
    "__________\n",
    "Transfert d'apprentissage (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "__Modélisation__\n",
    "\n",
    "On considère un problème d'apprentissage de logos (6 logos de marques de bière, en environnement réel). \n",
    "Comment modéliser le problème si : \n",
    "- a. on suppose qu'il n'y a qu'un seul logo par image ? \n",
    "- b. si on veut pouvoir reconnaître la présence de plusieurs logos par image ? \n",
    "\n",
    "a. --> apprentissage supervisé d'un pb de classification multi-classe (à chaque image d'entrainement est associé un unique label).\n",
    "\n",
    "b. --> apprentissage supervisé d'un pb de classification multi-label (à chaque image d'entrainement est associé un ensemble de labels / un vecteur de taille égale au nombre de classes, avec 1 si la classes est présente, 0 sinon)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. __Préparation des données__\n",
    "\n",
    "__Chargement__\n",
    "\n",
    "Les données sont disponibles sur [GoogleDrive](https://drive.usercontent.google.com/download?id=1ec2n18lbI71c0IS7RoixzAe3D67nlEgE&export=download). \n",
    "\n",
    "Les images sont groupées par classes (un dossier = une classe). Cela nous permet d'utiliser la fonction `datasets.ImageFolder` de PyTorch afin de charger les données (cf TPs précédents utilisation d'un DataLoader). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous êtes actuellement dans le répertoire : c:\\Users\\paula\\OneDrive\\Documents\\CentraleSupelec 2024\\Cours\\Mention IA\\Apprentissage profond\\TDs\\TD_DL\\3_transfer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Obtenir le chemin du répertoire courant\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Afficher le chemin\n",
    "print(f\"Vous êtes actuellement dans le répertoire : {current_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carlsberg', 'chimay', 'corona', 'fosters', 'guiness', 'tsingtao']\n"
     ]
    }
   ],
   "source": [
    "# on lit une première fois les images du dataset\n",
    "# TODO adapter le path selon l'endroit où sont stockées les données\n",
    "image_directory = \"eiffeillet/data/td3_data\"\n",
    "\n",
    "print(os.listdir(image_directory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalisation__\n",
    "\n",
    "Dans la suite, on va utiliser un modèle pré-entrainé sur le dataset ImageNet-1k (aussi appelé ILSVRC dataset, 1000 classes tirées de ImageNet-21k, 1.2 millions d'images). On applique aux données cibles une normalisation définie à partir des statistiques calculées sur le dataset source (moyenne et écarts types des valeurs des pixels, entre 0 et 1). On applique aussi un reformatage pour obtenir des images de 224 par 224 pixels.\n",
    "\n",
    "Dataset source = ImageNet-1k / \n",
    "Dataset cible = Beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n"
     ]
    }
   ],
   "source": [
    "# Normalisation des images pour les modèles pré-entraînés PyTorch\n",
    "# voir: https://pytorch.org/docs/stable/torchvision/models.html\n",
    "# et ici pour les « explications » sur les valeurs exactes: https://github.com/pytorch/vision/issues/1439\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# première lecture des données\n",
    "dataset_full = datasets.ImageFolder(image_directory, data_transforms)\n",
    "print(len(dataset_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Motivation__\n",
    "\n",
    "On dispose seulement de 420 images réparties en 6 classes ! Pas suffisant pour entrainer un réseau de neurones profond de plusieurs millions de paramètres... D'où l'intérêt d'utiliser les poids d'un modèle déjà entrainé sur un autre dataset de plus grande taille. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes : ['carlsberg', 'chimay', 'corona', 'fosters', 'guiness', 'tsingtao']\n",
      "Mapping class to index : {'carlsberg': 0, 'chimay': 1, 'corona': 2, 'fosters': 3, 'guiness': 4, 'tsingtao': 5}\n",
      "('eiffeillet/data/td3_data\\\\carlsberg\\\\1179199291.jpg', 0)\n"
     ]
    }
   ],
   "source": [
    "# some useful info\n",
    "print(\"Classes :\", dataset_full.classes)\n",
    "print(\"Mapping class to index :\", dataset_full.class_to_idx)\n",
    "print(dataset_full.samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz\n",
    "for ii in range(3) : \n",
    "    img_path, label = dataset_full.samples[ii]\n",
    "    with Image.open(img_path) as img:    \n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Partage des données__ \n",
    "\n",
    "Pour cela, utiliser la fonction [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) de scikit-learn) avec les proportions suivantes :\n",
    "- train = 60 % \n",
    "- val = 15 %\n",
    "- test = 25 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images de train : 336\n",
      "Nombre d'images de val : 84\n",
      "Nombre d'images de test : 105\n"
     ]
    }
   ],
   "source": [
    "# on split en train, val et test à partir de la liste complète\n",
    "np.random.seed(42)\n",
    "samples_train, samples_test = train_test_split(dataset_full.samples, test_size=0.25) # train+val vs test\n",
    "samples_train, samples_val = train_test_split(dataset_full.samples, test_size=0.2) # train vs val, 15/75 = 0.2\n",
    "\n",
    "print(\"Nombre d'images de train : %i\" % len(samples_train))\n",
    "print(\"Nombre d'images de val : %i\" % len(samples_val))\n",
    "print(\"Nombre d'images de test : %i\" % len(samples_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit un `DataLoader` pour chacun des sous-ensembles de données. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on définit les datasets et loaders pytorch à partir des listes d'images de train / val / test\n",
    "\n",
    "dataset_train = datasets.ImageFolder(image_directory, data_transforms)\n",
    "dataset_train.samples = samples_train\n",
    "dataset_train.imgs = samples_train\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=32, \n",
    "                                           shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_val = datasets.ImageFolder(image_directory, data_transforms)\n",
    "dataset_val.samples = samples_val\n",
    "dataset_val.imgs = samples_val\n",
    "\n",
    "dataset_test = datasets.ImageFolder(image_directory, data_transforms)\n",
    "dataset_test.samples = samples_test\n",
    "dataset_test.imgs = samples_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification : toutes les classes doivent être représentées dans le jeu de données d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage sur 6 classes\n"
     ]
    }
   ],
   "source": [
    "# détermination du nombre de classes (nb_classes=6)\n",
    "# vérification que les labels sont bien dans [0, nb_classes]\n",
    "labels=[x[1] for x in samples_train]\n",
    "if np.min(labels) != 0:\n",
    "    print(\"Error: labels should start at 0 (min is %i)\" % np.min(labels))\n",
    "    sys.exit(-1)\n",
    "if np.max(labels) != (len(np.unique(labels))-1):\n",
    "    print(\"Error: labels should go from 0 to Nclasses (max label = {}; Nclasse = {})\".format(np.max(labels),len(np.unique(labels)))  )\n",
    "    sys.exit(-1)\n",
    "nb_classes = np.max(labels)+1\n",
    "# nb_classes = len(dataset_train.classes)\n",
    "print(\"Apprentissage sur {} classes\".format(nb_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reproductibilité et sources d'aléatoire*\n",
    "\n",
    "A votre avis, où se situent les sources d'aléatoire lorsque vous entrainez un réseau de neurones avec un framework d'apprentissage profond (PyTorch / TensorFlow) ? Y-a-t-il des sources d'aléatoire à l'inférence ? \n",
    "\n",
    "Liens utiles : [documentation pytorch](https://pytorch.org/docs/stable/notes/randomness.html), [un exemple chez Weight&Biases](https://wandb.ai/sauravmaheshkar/RSNA-MICCAI/reports/How-to-Set-Random-Seeds-in-PyTorch-and-Tensorflow--VmlldzoxMDA2MDQy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136c0afff10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Chargement d'un modèle pré-entrainé__\n",
    "\n",
    "Ici on utilise un réseau convolutif de type ResNet18, pré-entrainé sur ImageNet-1k. \n",
    "NB : jeter un oeil aux [modèles disponibles via pytorch](https://pytorch.org/vision/stable/models.html). Pour les architecures à base de transformers, de nombreux modèles sont aussi disponibles via le hub et les librairies [huggingface](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération du ResNet-18 pré-entraîné...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\paula/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Récupérer un réseau pré-entraîné (resnet-18)\n",
    "print(\"Récupération du ResNet-18 pré-entraîné...\")\n",
    "my_net = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1') \n",
    "\n",
    "# The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
    "# The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. \n",
    "# You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# architecture\n",
    "print(my_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la dernière couche (fc) prend en entrée des vecteurs de taille 512."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transfert d'apprentissage\n",
    "\n",
    "Dans le cadre du transfert d'apprentissage, *on n'optimise pas les poids du réseau pr-entrainé sur nos données cibles*. On remplace simplement la couche de classification du réseau pré-entrainé par une nouvelle couche de classification, avec une taille adaptée au nombre de classes de notre problème. \n",
    "\n",
    "Pour apprendre à classer les images du dataset cible, on fige les poids du réseau pré-entrainé (partie \"extraction de caractéristiques\" / *feature extractor*) et on optimise les poids de la nouvelle couche de classification (partie \"décision\", une couche linéaire ici)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on indique qu'il est inutile de calculer les gradients des paramètres du réseau\n",
    "for param in my_net.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace la dernière couche fully connected à 1000 sorties (classes d'ImageNet) par une fully connected à 6 sorties (nos classes).\n",
    "# par défaut, les gradients des paramètres cette couche seront bien calculés\n",
    "#  NB: par défaut, la couche réinitialisée a .requires_grad=True\n",
    "my_net.fc = nn.Linear(in_features=512, out_features=6, bias=True)\n",
    "# on pourrait aussi réinitaliser d'autres couches e.g. my_net.layer4[1].conv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on utilisera le GPU (beaucoup plus rapide) si disponible, sinon on utilisera le CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\") # forcer en CPU s'il y a des problèmes de mémoire GPU (+ être patient...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net.to(device) # on utilise le GPU / CPU en fonction de ce qui est disponible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Entrainement et évaluation__\n",
    "\n",
    "On donne une fonction d'entrainement et une fonction d'évaluation (cf TPs précédents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on définit une fonction d'évaluation\n",
    "def evaluate(model, dataset, criterion):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "    for data in loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        n_correct = torch.sum(preds == labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        avg_accuracy += n_correct\n",
    "        \n",
    "    return avg_loss / len(dataset), float(avg_accuracy) / len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction classique d'entraînement d'un modèle, voir TDs précédents\n",
    "PRINT_LOSS = True\n",
    "def train_model(model, loader_train, data_val, optimizer, criterion, n_epochs=10):\n",
    "    for epoch in range(n_epochs): # à chaque epochs\n",
    "        print(\"EPOCH % i\" % epoch)\n",
    "        for i, data in enumerate(loader_train): # itère sur les minibatchs via le loader apprentissage\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # on passe les données sur CPU / GPU\n",
    "            optimizer.zero_grad() # on réinitialise les gradients\n",
    "            outputs = model(inputs) # on calcule l'output\n",
    "            \n",
    "            loss = criterion(outputs, labels) # on calcule la loss\n",
    "            if PRINT_LOSS:\n",
    "                model.train(False)\n",
    "                loss_val, accuracy = evaluate(my_net, data_val, criterion)\n",
    "                model.train(True)\n",
    "                print(\"{} loss train: {:1.4f}\\t val {:1.4f}\\tAcc (val): {:.1%}\".format(i, loss.item(), loss_val, accuracy   ))\n",
    "            \n",
    "            loss.backward() # on effectue la backprop pour calculer les gradients\n",
    "            optimizer.step() # on update les gradients en fonction des paramètres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une fonction de coût et un optimiseur. On utilise un faible taux d'apprentissage (learning rate fixé à 0.001) car on n'a besoin que d'optimiser la dernière couche du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_net.fc.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apprentissage en transfer learning\n",
      "EPOCH  0\n",
      "0 loss train: 1.7534\t val 0.1419\tAcc (val): 10.7%\n",
      "1 loss train: 1.8068\t val 0.1413\tAcc (val): 11.9%\n",
      "2 loss train: 1.8363\t val 0.1403\tAcc (val): 13.1%\n",
      "3 loss train: 1.7731\t val 0.1386\tAcc (val): 14.3%\n",
      "4 loss train: 1.9347\t val 0.1365\tAcc (val): 14.3%\n",
      "5 loss train: 1.8747\t val 0.1340\tAcc (val): 15.5%\n",
      "6 loss train: 1.8335\t val 0.1323\tAcc (val): 22.6%\n",
      "7 loss train: 1.8733\t val 0.1311\tAcc (val): 20.2%\n",
      "8 loss train: 1.8097\t val 0.1299\tAcc (val): 23.8%\n",
      "9 loss train: 1.7033\t val 0.1288\tAcc (val): 21.4%\n",
      "10 loss train: 1.7140\t val 0.1281\tAcc (val): 20.2%\n",
      "EPOCH  1\n",
      "0 loss train: 1.6978\t val 0.1270\tAcc (val): 21.4%\n",
      "1 loss train: 1.5865\t val 0.1262\tAcc (val): 22.6%\n",
      "2 loss train: 1.7872\t val 0.1260\tAcc (val): 23.8%\n",
      "3 loss train: 1.7322\t val 0.1249\tAcc (val): 25.0%\n",
      "4 loss train: 1.5494\t val 0.1235\tAcc (val): 25.0%\n",
      "5 loss train: 1.5903\t val 0.1214\tAcc (val): 31.0%\n",
      "6 loss train: 1.6974\t val 0.1196\tAcc (val): 32.1%\n",
      "7 loss train: 1.5923\t val 0.1173\tAcc (val): 34.5%\n",
      "8 loss train: 1.5709\t val 0.1145\tAcc (val): 40.5%\n",
      "9 loss train: 1.5696\t val 0.1121\tAcc (val): 41.7%\n",
      "10 loss train: 1.6378\t val 0.1104\tAcc (val): 47.6%\n",
      "EPOCH  2\n",
      "0 loss train: 1.4733\t val 0.1088\tAcc (val): 46.4%\n",
      "1 loss train: 1.4950\t val 0.1074\tAcc (val): 45.2%\n",
      "2 loss train: 1.4964\t val 0.1063\tAcc (val): 47.6%\n",
      "3 loss train: 1.4172\t val 0.1047\tAcc (val): 47.6%\n",
      "4 loss train: 1.3914\t val 0.1034\tAcc (val): 53.6%\n",
      "5 loss train: 1.4375\t val 0.1018\tAcc (val): 58.3%\n",
      "6 loss train: 1.4212\t val 0.1009\tAcc (val): 58.3%\n",
      "7 loss train: 1.3309\t val 0.0999\tAcc (val): 54.8%\n",
      "8 loss train: 1.3356\t val 0.0989\tAcc (val): 56.0%\n",
      "9 loss train: 1.3418\t val 0.0984\tAcc (val): 56.0%\n",
      "10 loss train: 1.3532\t val 0.0973\tAcc (val): 58.3%\n",
      "EPOCH  3\n",
      "0 loss train: 1.2807\t val 0.0974\tAcc (val): 58.3%\n",
      "1 loss train: 1.2158\t val 0.0971\tAcc (val): 58.3%\n",
      "2 loss train: 1.1521\t val 0.0968\tAcc (val): 57.1%\n",
      "3 loss train: 1.2927\t val 0.0964\tAcc (val): 56.0%\n",
      "4 loss train: 1.2288\t val 0.0962\tAcc (val): 56.0%\n",
      "5 loss train: 1.1469\t val 0.0961\tAcc (val): 54.8%\n",
      "6 loss train: 1.3566\t val 0.0953\tAcc (val): 57.1%\n",
      "7 loss train: 0.9921\t val 0.0941\tAcc (val): 58.3%\n",
      "8 loss train: 1.2646\t val 0.0923\tAcc (val): 59.5%\n",
      "9 loss train: 1.2891\t val 0.0911\tAcc (val): 59.5%\n",
      "10 loss train: 1.2214\t val 0.0888\tAcc (val): 63.1%\n",
      "EPOCH  4\n",
      "0 loss train: 1.2025\t val 0.0866\tAcc (val): 67.9%\n",
      "1 loss train: 1.0702\t val 0.0852\tAcc (val): 66.7%\n",
      "2 loss train: 1.1332\t val 0.0844\tAcc (val): 65.5%\n",
      "3 loss train: 1.2555\t val 0.0833\tAcc (val): 63.1%\n",
      "4 loss train: 1.0492\t val 0.0819\tAcc (val): 64.3%\n",
      "5 loss train: 1.0737\t val 0.0809\tAcc (val): 70.2%\n",
      "6 loss train: 0.8957\t val 0.0801\tAcc (val): 69.0%\n",
      "7 loss train: 0.9412\t val 0.0793\tAcc (val): 66.7%\n",
      "8 loss train: 1.0304\t val 0.0790\tAcc (val): 63.1%\n",
      "9 loss train: 1.0462\t val 0.0785\tAcc (val): 65.5%\n",
      "10 loss train: 1.1706\t val 0.0784\tAcc (val): 65.5%\n",
      "EPOCH  5\n",
      "0 loss train: 0.9069\t val 0.0776\tAcc (val): 66.7%\n",
      "1 loss train: 1.0675\t val 0.0774\tAcc (val): 67.9%\n",
      "2 loss train: 0.9705\t val 0.0771\tAcc (val): 67.9%\n",
      "3 loss train: 0.8302\t val 0.0772\tAcc (val): 67.9%\n",
      "4 loss train: 1.0768\t val 0.0771\tAcc (val): 69.0%\n",
      "5 loss train: 0.9559\t val 0.0767\tAcc (val): 72.6%\n",
      "6 loss train: 0.9187\t val 0.0765\tAcc (val): 72.6%\n",
      "7 loss train: 0.8967\t val 0.0761\tAcc (val): 75.0%\n",
      "8 loss train: 0.8330\t val 0.0749\tAcc (val): 75.0%\n",
      "9 loss train: 1.0867\t val 0.0738\tAcc (val): 73.8%\n",
      "10 loss train: 0.9299\t val 0.0729\tAcc (val): 69.0%\n",
      "EPOCH  6\n",
      "0 loss train: 0.9688\t val 0.0725\tAcc (val): 72.6%\n",
      "1 loss train: 1.0896\t val 0.0719\tAcc (val): 70.2%\n",
      "2 loss train: 0.8051\t val 0.0721\tAcc (val): 70.2%\n",
      "3 loss train: 0.7988\t val 0.0732\tAcc (val): 70.2%\n",
      "4 loss train: 0.8570\t val 0.0732\tAcc (val): 66.7%\n",
      "5 loss train: 1.1196\t val 0.0732\tAcc (val): 63.1%\n",
      "6 loss train: 1.0513\t val 0.0728\tAcc (val): 63.1%\n",
      "7 loss train: 0.9218\t val 0.0718\tAcc (val): 64.3%\n",
      "8 loss train: 0.7766\t val 0.0699\tAcc (val): 67.9%\n",
      "9 loss train: 0.8110\t val 0.0686\tAcc (val): 70.2%\n",
      "10 loss train: 1.0155\t val 0.0678\tAcc (val): 71.4%\n",
      "EPOCH  7\n",
      "0 loss train: 0.8059\t val 0.0668\tAcc (val): 76.2%\n",
      "1 loss train: 0.8052\t val 0.0666\tAcc (val): 75.0%\n",
      "2 loss train: 0.7445\t val 0.0665\tAcc (val): 75.0%\n",
      "3 loss train: 0.8529\t val 0.0663\tAcc (val): 75.0%\n",
      "4 loss train: 0.7291\t val 0.0659\tAcc (val): 75.0%\n",
      "5 loss train: 0.7469\t val 0.0654\tAcc (val): 75.0%\n",
      "6 loss train: 0.9114\t val 0.0653\tAcc (val): 72.6%\n",
      "7 loss train: 0.7283\t val 0.0647\tAcc (val): 73.8%\n",
      "8 loss train: 0.7610\t val 0.0645\tAcc (val): 76.2%\n",
      "9 loss train: 0.7644\t val 0.0644\tAcc (val): 75.0%\n",
      "10 loss train: 0.8356\t val 0.0643\tAcc (val): 76.2%\n",
      "EPOCH  8\n",
      "0 loss train: 0.6967\t val 0.0640\tAcc (val): 76.2%\n",
      "1 loss train: 0.8420\t val 0.0639\tAcc (val): 75.0%\n",
      "2 loss train: 0.6616\t val 0.0636\tAcc (val): 75.0%\n",
      "3 loss train: 0.7586\t val 0.0633\tAcc (val): 76.2%\n",
      "4 loss train: 0.8396\t val 0.0633\tAcc (val): 77.4%\n",
      "5 loss train: 0.7530\t val 0.0632\tAcc (val): 78.6%\n",
      "6 loss train: 0.6266\t val 0.0631\tAcc (val): 75.0%\n",
      "7 loss train: 0.8046\t val 0.0631\tAcc (val): 73.8%\n",
      "8 loss train: 0.7083\t val 0.0628\tAcc (val): 73.8%\n",
      "9 loss train: 0.6794\t val 0.0626\tAcc (val): 76.2%\n",
      "10 loss train: 0.9513\t val 0.0624\tAcc (val): 73.8%\n",
      "EPOCH  9\n",
      "0 loss train: 0.7394\t val 0.0617\tAcc (val): 75.0%\n",
      "1 loss train: 0.6880\t val 0.0615\tAcc (val): 73.8%\n",
      "2 loss train: 0.7020\t val 0.0609\tAcc (val): 73.8%\n",
      "3 loss train: 0.7637\t val 0.0610\tAcc (val): 71.4%\n",
      "4 loss train: 0.6947\t val 0.0606\tAcc (val): 72.6%\n",
      "5 loss train: 0.6814\t val 0.0606\tAcc (val): 71.4%\n",
      "6 loss train: 0.5930\t val 0.0601\tAcc (val): 71.4%\n",
      "7 loss train: 0.7222\t val 0.0600\tAcc (val): 73.8%\n",
      "8 loss train: 0.6900\t val 0.0599\tAcc (val): 72.6%\n",
      "9 loss train: 0.7146\t val 0.0596\tAcc (val): 73.8%\n",
      "10 loss train: 0.5931\t val 0.0594\tAcc (val): 75.0%\n"
     ]
    }
   ],
   "source": [
    "my_net.train(True) # NB : pas indispensable ici comme on a fixé la partie extraction de features, \n",
    "# mais bonne pratique de façon générale\n",
    "# permet notamment d'activer / désactiver le dropout selon qu'on entraîne ou teste le modèle\n",
    "print(\"\\nApprentissage en transfer learning\")\n",
    "\n",
    "train_model(my_net, loader_train, dataset_val, optimizer, criterion, n_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test): 85.7%\n"
     ]
    }
   ],
   "source": [
    "# évaluation\n",
    "my_net.train(False)\n",
    "loss, accuracy = evaluate(my_net, dataset_test, criterion)\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Adaptation fine des poids du réseau (*fine-tuning*)\n",
    "\n",
    "On réinitialise le réseau. Cette fois-ci, on va en utiliser les images de notre dataset cible pour mettre à jour (en totalité ou en partie) les paramètres du modèle dans les couches antérieures à la couche de décision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on réinitialise le modèle resnet\n",
    "my_net = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1') \n",
    "\n",
    "my_net.fc = nn.Linear(in_features=my_net.fc.in_features, out_features=nb_classes, bias=True)\n",
    "my_net.to(device)\n",
    "\n",
    "# cette fois on veut mettre à jour tous les paramètres\n",
    "params_to_update = my_net.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque :  il est possible de ne sélectionner que quelques couches (plutôt parmi les \"dernières\", les plus proches de la couche de classificaiton et du calcul de la fonction de coût)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine tune  layer4.1.conv2.weight\n",
      "fine tune  layer4.1.bn2.weight\n",
      "fine tune  fc.weight\n",
      "fine tune  fc.bias\n",
      "Couches mises à jour :\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "# ici on restreint les couches dont on veut mettre à jour les paramètres\n",
    "\n",
    "list_of_layers_to_finetune=['fc.weight','fc.bias','layer4.1.conv2.weight','layer4.1.bn2. bias','layer4.1.bn2.weight']\n",
    "\n",
    "params_to_update=[]\n",
    "for name,param in my_net.named_parameters():\n",
    "    if name in list_of_layers_to_finetune:\n",
    "        print(\"fine tune \",name)\n",
    "        params_to_update.append(param)\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# sanity check \n",
    "print(\"Couches mises à jour :\")\n",
    "for name, param in my_net.named_parameters() : \n",
    "    if param.requires_grad :\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise un taux d'apprentissage relativement bas, on ne veut pas modifier brutalement les poids du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition de la fonction de coût et de l'optimiseur \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage avec fine-tuning\n",
      "EPOCH  0\n",
      "0 loss train: 2.1293\t val 0.1519\tAcc (val): 21.4%\n",
      "1 loss train: 2.0108\t val 0.1476\tAcc (val): 21.4%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m my_net\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, loader_train, data_val, optimizer, criterion, n_epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PRINT_LOSS:\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m     loss_val, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m loss train: \u001b[39m\u001b[38;5;132;01m{:1.4f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m val \u001b[39m\u001b[38;5;132;01m{:1.4f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAcc (val): \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, loss\u001b[38;5;241m.\u001b[39mitem(), loss_val, accuracy   ))\n",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, dataset, criterion)\u001b[0m\n\u001b[0;32m      4\u001b[0m avg_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      7\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      8\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\paula\\miniconda3\\envs\\deepl\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# on ré-entraîne\n",
    "print(\"Apprentissage avec fine-tuning\")\n",
    "my_net.train(True)\n",
    "torch.manual_seed(42)\n",
    "train_model(my_net, loader_train, dataset_val, optimizer, criterion, n_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test): 88.6%\n"
     ]
    }
   ],
   "source": [
    "# on ré-évalue les performances\n",
    "my_net.train(False)\n",
    "loss, accuracy = evaluate(my_net, dataset_test, criterion)\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Autre architecture \n",
    "\n",
    "On a utilisé un réseau de type ResNet18 avec 10M de paramètres. Ici on se propose d'utiliser une architecture plus compacte : MobileNetv2 (), qui comporte 2.3M de paramètres. Comparer les architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# on définit un réseau avec une nouvelle architecture\n",
    "my_net = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V1')\n",
    "print(my_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504872\n",
      "3504872\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in my_net.parameters()))\n",
    "print(sum(p.numel() for p in my_net.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note que cette architecture ne comporte pas de module `fc` accessible directement comme pour ResNet18 dans la partie précédente. La structure est `features` puis `classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage avec fine-tuning\n",
      "\n",
      "EPOCH  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss train: 1.8987\t val 0.1297\tAcc (val): 14.3%\n",
      "1 loss train: 1.9521\t val 0.1296\tAcc (val): 14.3%\n",
      "2 loss train: 1.8467\t val 0.1291\tAcc (val): 14.3%\n",
      "3 loss train: 1.8029\t val 0.1283\tAcc (val): 17.9%\n",
      "4 loss train: 1.7781\t val 0.1272\tAcc (val): 19.0%\n",
      "5 loss train: 1.8120\t val 0.1260\tAcc (val): 22.6%\n",
      "6 loss train: 1.7640\t val 0.1245\tAcc (val): 27.4%\n",
      "7 loss train: 1.7460\t val 0.1229\tAcc (val): 28.6%\n",
      "8 loss train: 1.6568\t val 0.1210\tAcc (val): 32.1%\n",
      "9 loss train: 1.7055\t val 0.1195\tAcc (val): 32.1%\n",
      "10 loss train: 1.6745\t val 0.1175\tAcc (val): 33.3%\n",
      "EPOCH  1\n",
      "0 loss train: 1.5993\t val 0.1158\tAcc (val): 33.3%\n",
      "1 loss train: 1.4815\t val 0.1138\tAcc (val): 35.7%\n",
      "2 loss train: 1.5627\t val 0.1121\tAcc (val): 36.9%\n",
      "3 loss train: 1.4500\t val 0.1097\tAcc (val): 39.3%\n",
      "4 loss train: 1.3949\t val 0.1074\tAcc (val): 46.4%\n",
      "5 loss train: 1.3257\t val 0.1048\tAcc (val): 53.6%\n",
      "6 loss train: 1.3313\t val 0.1022\tAcc (val): 58.3%\n",
      "7 loss train: 1.3466\t val 0.0995\tAcc (val): 63.1%\n",
      "8 loss train: 1.2609\t val 0.0970\tAcc (val): 64.3%\n",
      "9 loss train: 1.1633\t val 0.0936\tAcc (val): 67.9%\n",
      "10 loss train: 1.0879\t val 0.0909\tAcc (val): 70.2%\n",
      "EPOCH  2\n",
      "0 loss train: 1.0525\t val 0.0883\tAcc (val): 72.6%\n",
      "1 loss train: 1.1258\t val 0.0856\tAcc (val): 72.6%\n",
      "2 loss train: 1.0833\t val 0.0830\tAcc (val): 71.4%\n",
      "3 loss train: 0.9669\t val 0.0803\tAcc (val): 73.8%\n",
      "4 loss train: 0.9634\t val 0.0783\tAcc (val): 73.8%\n",
      "5 loss train: 0.8042\t val 0.0758\tAcc (val): 75.0%\n",
      "6 loss train: 0.8784\t val 0.0736\tAcc (val): 73.8%\n",
      "7 loss train: 0.7924\t val 0.0716\tAcc (val): 77.4%\n",
      "8 loss train: 0.8889\t val 0.0694\tAcc (val): 77.4%\n",
      "9 loss train: 0.8458\t val 0.0675\tAcc (val): 77.4%\n",
      "10 loss train: 0.8176\t val 0.0654\tAcc (val): 76.2%\n",
      "EPOCH  3\n",
      "0 loss train: 0.6396\t val 0.0628\tAcc (val): 81.0%\n",
      "1 loss train: 0.6315\t val 0.0606\tAcc (val): 78.6%\n",
      "2 loss train: 0.6611\t val 0.0586\tAcc (val): 79.8%\n",
      "3 loss train: 0.6393\t val 0.0570\tAcc (val): 78.6%\n",
      "4 loss train: 0.5968\t val 0.0550\tAcc (val): 78.6%\n",
      "5 loss train: 0.6899\t val 0.0534\tAcc (val): 79.8%\n",
      "6 loss train: 0.6901\t val 0.0514\tAcc (val): 79.8%\n",
      "7 loss train: 0.5203\t val 0.0491\tAcc (val): 82.1%\n",
      "8 loss train: 0.5500\t val 0.0473\tAcc (val): 82.1%\n",
      "9 loss train: 0.5271\t val 0.0458\tAcc (val): 83.3%\n",
      "10 loss train: 0.5889\t val 0.0448\tAcc (val): 83.3%\n",
      "EPOCH  4\n",
      "0 loss train: 0.4552\t val 0.0430\tAcc (val): 84.5%\n",
      "1 loss train: 0.4657\t val 0.0417\tAcc (val): 84.5%\n",
      "2 loss train: 0.3470\t val 0.0408\tAcc (val): 85.7%\n",
      "3 loss train: 0.2962\t val 0.0399\tAcc (val): 85.7%\n",
      "4 loss train: 0.4314\t val 0.0388\tAcc (val): 85.7%\n",
      "5 loss train: 0.4151\t val 0.0377\tAcc (val): 84.5%\n",
      "6 loss train: 0.2953\t val 0.0370\tAcc (val): 85.7%\n",
      "7 loss train: 0.3188\t val 0.0361\tAcc (val): 85.7%\n",
      "8 loss train: 0.3944\t val 0.0353\tAcc (val): 86.9%\n",
      "9 loss train: 0.3455\t val 0.0346\tAcc (val): 86.9%\n",
      "10 loss train: 0.4708\t val 0.0337\tAcc (val): 86.9%\n",
      "EPOCH  5\n",
      "0 loss train: 0.2894\t val 0.0329\tAcc (val): 88.1%\n",
      "1 loss train: 0.3019\t val 0.0319\tAcc (val): 88.1%\n",
      "2 loss train: 0.3164\t val 0.0309\tAcc (val): 88.1%\n",
      "3 loss train: 0.2718\t val 0.0299\tAcc (val): 89.3%\n",
      "4 loss train: 0.3227\t val 0.0295\tAcc (val): 89.3%\n",
      "5 loss train: 0.2182\t val 0.0291\tAcc (val): 90.5%\n",
      "6 loss train: 0.2988\t val 0.0290\tAcc (val): 89.3%\n",
      "7 loss train: 0.2005\t val 0.0284\tAcc (val): 90.5%\n",
      "8 loss train: 0.2514\t val 0.0275\tAcc (val): 90.5%\n",
      "9 loss train: 0.2473\t val 0.0270\tAcc (val): 90.5%\n",
      "10 loss train: 0.2486\t val 0.0267\tAcc (val): 90.5%\n",
      "EPOCH  6\n",
      "0 loss train: 0.2251\t val 0.0260\tAcc (val): 90.5%\n",
      "1 loss train: 0.2092\t val 0.0258\tAcc (val): 90.5%\n",
      "2 loss train: 0.1785\t val 0.0255\tAcc (val): 89.3%\n",
      "3 loss train: 0.2513\t val 0.0255\tAcc (val): 90.5%\n",
      "4 loss train: 0.1277\t val 0.0252\tAcc (val): 90.5%\n",
      "5 loss train: 0.1699\t val 0.0250\tAcc (val): 90.5%\n",
      "6 loss train: 0.2277\t val 0.0251\tAcc (val): 90.5%\n",
      "7 loss train: 0.1501\t val 0.0246\tAcc (val): 89.3%\n",
      "8 loss train: 0.1504\t val 0.0244\tAcc (val): 89.3%\n",
      "9 loss train: 0.2704\t val 0.0242\tAcc (val): 88.1%\n",
      "10 loss train: 0.1019\t val 0.0238\tAcc (val): 90.5%\n",
      "EPOCH  7\n",
      "0 loss train: 0.1248\t val 0.0234\tAcc (val): 90.5%\n",
      "1 loss train: 0.2032\t val 0.0234\tAcc (val): 90.5%\n",
      "2 loss train: 0.1158\t val 0.0229\tAcc (val): 90.5%\n",
      "3 loss train: 0.1472\t val 0.0228\tAcc (val): 90.5%\n",
      "4 loss train: 0.1758\t val 0.0224\tAcc (val): 90.5%\n",
      "5 loss train: 0.1159\t val 0.0221\tAcc (val): 90.5%\n",
      "6 loss train: 0.1162\t val 0.0218\tAcc (val): 91.7%\n",
      "7 loss train: 0.1060\t val 0.0217\tAcc (val): 91.7%\n",
      "8 loss train: 0.0800\t val 0.0214\tAcc (val): 91.7%\n",
      "9 loss train: 0.1626\t val 0.0212\tAcc (val): 90.5%\n",
      "10 loss train: 0.1013\t val 0.0212\tAcc (val): 90.5%\n",
      "EPOCH  8\n",
      "0 loss train: 0.0941\t val 0.0210\tAcc (val): 89.3%\n",
      "1 loss train: 0.0981\t val 0.0209\tAcc (val): 90.5%\n",
      "2 loss train: 0.1598\t val 0.0206\tAcc (val): 90.5%\n",
      "3 loss train: 0.1336\t val 0.0205\tAcc (val): 90.5%\n",
      "4 loss train: 0.0936\t val 0.0205\tAcc (val): 90.5%\n",
      "5 loss train: 0.0688\t val 0.0203\tAcc (val): 90.5%\n",
      "6 loss train: 0.0753\t val 0.0203\tAcc (val): 90.5%\n",
      "7 loss train: 0.0716\t val 0.0202\tAcc (val): 89.3%\n",
      "8 loss train: 0.1465\t val 0.0201\tAcc (val): 90.5%\n",
      "9 loss train: 0.1229\t val 0.0198\tAcc (val): 89.3%\n",
      "10 loss train: 0.2022\t val 0.0196\tAcc (val): 90.5%\n",
      "EPOCH  9\n",
      "0 loss train: 0.0779\t val 0.0194\tAcc (val): 91.7%\n",
      "1 loss train: 0.0631\t val 0.0195\tAcc (val): 91.7%\n",
      "2 loss train: 0.0981\t val 0.0194\tAcc (val): 90.5%\n",
      "3 loss train: 0.0733\t val 0.0195\tAcc (val): 90.5%\n",
      "4 loss train: 0.0785\t val 0.0195\tAcc (val): 90.5%\n",
      "5 loss train: 0.0680\t val 0.0194\tAcc (val): 90.5%\n",
      "6 loss train: 0.0811\t val 0.0192\tAcc (val): 90.5%\n",
      "7 loss train: 0.0774\t val 0.0189\tAcc (val): 90.5%\n",
      "8 loss train: 0.0646\t val 0.0190\tAcc (val): 89.3%\n",
      "9 loss train: 0.0515\t val 0.0189\tAcc (val): 90.5%\n",
      "10 loss train: 0.1288\t val 0.0187\tAcc (val): 90.5%\n",
      "\n",
      "Accuracy (test): 98.1%\n"
     ]
    }
   ],
   "source": [
    "# remplacement de la couche de classification\n",
    "my_net.classifier[1] = nn.Linear(in_features=my_net.classifier[1].in_features, out_features=nb_classes, bias=True)\n",
    "my_net.to(device)\n",
    "\n",
    "# mise à jour de tous les paramètres\n",
    "params_to_update = my_net.parameters()\n",
    "\n",
    "# définition de la fonction de coût et de l'optimiseur \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# entrainement\n",
    "print(\"Apprentissage avec fine-tuning\\n\")\n",
    "my_net.train(True)\n",
    "torch.manual_seed(42)\n",
    "train_model(my_net, loader_train, dataset_val, optimizer, criterion, n_epochs=10)\n",
    "\n",
    "# évaluation des performances\n",
    "my_net.train(False)\n",
    "loss, accuracy = evaluate(my_net, dataset_test, criterion)\n",
    "print(\"\\nAccuracy (test): %.1f%%\" % (100 * accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bonus : modélisation multi-labels\n",
    "\n",
    "En conservant l’hypothèse de classes exclusives (qui est fausse en pratique mais facilite l’annotation) il est néanmoins possible d’apprendre un modèle multi-labels, où chaque classe est reconnue indépendamment. \n",
    "\n",
    "Points d'attentions : \n",
    "- ici on ne refait pas la labelisation des données, mais on modifie la manière d'entrainer le réseau, pour pouvoir faire une prédiction multi-label  \n",
    "\n",
    "- définition de la fonction de coût \n",
    "> criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "- seuil par défaut pour attribuer un label : 0.5\n",
    "\n",
    "- possibilité de déterminer un seuil de décision pour chacune des classes en se basant sur le dataset de validation.\n",
    "\n",
    "- One-hot-encoding avec `torch.nn.one_hot_encoding` cf [documentation](https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html). Attention, si on ne précise pas le nombre de classes, celui-ci est inféré à partir du nombre de labels différents au sein d'un batch, mais cela peut conduire à une erreur si toutes les classes du problème ne sont pas représentées dans un batch donné. D'où l'intérêt de préciser le nombre de classes avec l'argument `num_classes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on redéfinit la fonction d'évaluation\n",
    "# one-hot encoding des labels pour calculer la BCELoss\n",
    "# pour l'accuracy, comme on ne dispose pas de la vérité terrain pour le cas multilabel, \n",
    "# on se rapporte au cas précédent avec un seul label. \n",
    " \n",
    "def evaluate(model, dataset, criterion):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    for data in loader:\n",
    "        inputs, labels = data\n",
    "        oh_labels = torch.nn.functional.one_hot(labels, num_classes = nb_classes) \n",
    "        oh_labels = oh_labels.type(torch.FloatTensor)\n",
    "        inputs, oh_labels = inputs.to(device), oh_labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, oh_labels)\n",
    "        _, preds = torch.max(outputs, 1) \n",
    "        n_correct = torch.sum(preds.to(\"cpu\") == labels)\n",
    "        # autre méthode\n",
    "        # pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        # gt = oh_labels.argmax(dim=1, keepdim=True)\n",
    "        # n_correct = pred.eq(gt.view_as(pred)).sum().item()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        avg_accuracy += n_correct\n",
    "        \n",
    "    return avg_loss / len(dataset), float(avg_accuracy) / len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction classique d'entraînement d'un modèle, voir TDs précédents\n",
    "PRINT_LOSS = True\n",
    "def train_model(model, loader_train, data_val, optimizer, criterion, n_epochs=10):\n",
    "    for epoch in range(n_epochs): # à chaque epochs\n",
    "        print(\"EPOCH % i\" % epoch)\n",
    "        for i, data in enumerate(loader_train): # itère sur les minibatchs via le loader apprentissage\n",
    "            inputs, labels = data\n",
    "            labels = torch.nn.functional.one_hot(labels, num_classes = nb_classes)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # on passe les données sur CPU / GPU\n",
    "            optimizer.zero_grad() # on réinitialise les gradients\n",
    "            outputs = model(inputs) # on calcule l'output\n",
    "            \n",
    "            loss = criterion(outputs, labels) # on calcule la loss\n",
    "            if PRINT_LOSS:\n",
    "                model.train(False)\n",
    "                loss_val, accuracy = evaluate(model, data_val, criterion)\n",
    "                model.train(True)\n",
    "                print(\"{} loss train: {:1.4f}\\t val {:1.4f}\\tAcc (val): {:.1%}\".format(i, loss.item(), loss_val, accuracy   ))\n",
    "            \n",
    "            loss.backward() # on effectue la backprop pour calculer les gradients\n",
    "            optimizer.step() # on update les gradients en fonction des paramètres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage avec fine-tuning\n",
      "EPOCH  0\n",
      "0 loss train: 0.6874\t val 0.0226\tAcc (val): 21.4%\n",
      "1 loss train: 0.6945\t val 0.0225\tAcc (val): 21.4%\n",
      "2 loss train: 0.6830\t val 0.0223\tAcc (val): 21.4%\n",
      "3 loss train: 0.6604\t val 0.0219\tAcc (val): 21.4%\n",
      "4 loss train: 0.6131\t val 0.0214\tAcc (val): 21.4%\n",
      "5 loss train: 0.6184\t val 0.0209\tAcc (val): 20.2%\n",
      "6 loss train: 0.6098\t val 0.0203\tAcc (val): 20.2%\n",
      "7 loss train: 0.5796\t val 0.0197\tAcc (val): 20.2%\n",
      "8 loss train: 0.5512\t val 0.0191\tAcc (val): 22.6%\n",
      "9 loss train: 0.5464\t val 0.0186\tAcc (val): 22.6%\n",
      "10 loss train: 0.5355\t val 0.0180\tAcc (val): 25.0%\n",
      "EPOCH  1\n",
      "0 loss train: 0.4937\t val 0.0175\tAcc (val): 27.4%\n",
      "1 loss train: 0.5018\t val 0.0171\tAcc (val): 28.6%\n",
      "2 loss train: 0.5003\t val 0.0168\tAcc (val): 31.0%\n",
      "3 loss train: 0.4741\t val 0.0165\tAcc (val): 32.1%\n",
      "4 loss train: 0.4761\t val 0.0162\tAcc (val): 32.1%\n",
      "5 loss train: 0.4520\t val 0.0160\tAcc (val): 34.5%\n",
      "6 loss train: 0.4743\t val 0.0159\tAcc (val): 34.5%\n",
      "7 loss train: 0.4436\t val 0.0157\tAcc (val): 33.3%\n",
      "8 loss train: 0.4628\t val 0.0156\tAcc (val): 33.3%\n",
      "9 loss train: 0.4434\t val 0.0156\tAcc (val): 34.5%\n",
      "10 loss train: 0.4351\t val 0.0155\tAcc (val): 34.5%\n",
      "EPOCH  2\n",
      "0 loss train: 0.4366\t val 0.0155\tAcc (val): 36.9%\n",
      "1 loss train: 0.4259\t val 0.0154\tAcc (val): 36.9%\n",
      "2 loss train: 0.4351\t val 0.0154\tAcc (val): 38.1%\n",
      "3 loss train: 0.4467\t val 0.0154\tAcc (val): 40.5%\n",
      "4 loss train: 0.4294\t val 0.0153\tAcc (val): 44.0%\n",
      "5 loss train: 0.4313\t val 0.0153\tAcc (val): 44.0%\n",
      "6 loss train: 0.4406\t val 0.0153\tAcc (val): 45.2%\n",
      "7 loss train: 0.4286\t val 0.0153\tAcc (val): 44.0%\n",
      "8 loss train: 0.4301\t val 0.0152\tAcc (val): 46.4%\n",
      "9 loss train: 0.4378\t val 0.0152\tAcc (val): 48.8%\n",
      "10 loss train: 0.4236\t val 0.0152\tAcc (val): 48.8%\n",
      "EPOCH  3\n",
      "0 loss train: 0.4099\t val 0.0151\tAcc (val): 50.0%\n",
      "1 loss train: 0.4237\t val 0.0151\tAcc (val): 51.2%\n",
      "2 loss train: 0.4378\t val 0.0150\tAcc (val): 51.2%\n",
      "3 loss train: 0.4362\t val 0.0150\tAcc (val): 51.2%\n",
      "4 loss train: 0.4192\t val 0.0150\tAcc (val): 52.4%\n",
      "5 loss train: 0.4152\t val 0.0149\tAcc (val): 53.6%\n",
      "6 loss train: 0.4171\t val 0.0148\tAcc (val): 56.0%\n",
      "7 loss train: 0.4150\t val 0.0148\tAcc (val): 54.8%\n",
      "8 loss train: 0.4182\t val 0.0147\tAcc (val): 58.3%\n",
      "9 loss train: 0.4125\t val 0.0147\tAcc (val): 57.1%\n",
      "10 loss train: 0.4167\t val 0.0146\tAcc (val): 57.1%\n",
      "EPOCH  4\n",
      "0 loss train: 0.3999\t val 0.0145\tAcc (val): 58.3%\n",
      "1 loss train: 0.4088\t val 0.0145\tAcc (val): 58.3%\n",
      "2 loss train: 0.4048\t val 0.0144\tAcc (val): 61.9%\n",
      "3 loss train: 0.3891\t val 0.0144\tAcc (val): 61.9%\n",
      "4 loss train: 0.4154\t val 0.0143\tAcc (val): 61.9%\n",
      "5 loss train: 0.3983\t val 0.0142\tAcc (val): 61.9%\n",
      "6 loss train: 0.3837\t val 0.0142\tAcc (val): 63.1%\n",
      "7 loss train: 0.3760\t val 0.0141\tAcc (val): 63.1%\n",
      "8 loss train: 0.3932\t val 0.0141\tAcc (val): 65.5%\n",
      "9 loss train: 0.4002\t val 0.0140\tAcc (val): 66.7%\n",
      "10 loss train: 0.4004\t val 0.0139\tAcc (val): 66.7%\n",
      "EPOCH  5\n",
      "0 loss train: 0.3897\t val 0.0139\tAcc (val): 66.7%\n",
      "1 loss train: 0.3879\t val 0.0138\tAcc (val): 67.9%\n",
      "2 loss train: 0.3782\t val 0.0138\tAcc (val): 67.9%\n",
      "3 loss train: 0.3684\t val 0.0137\tAcc (val): 69.0%\n",
      "4 loss train: 0.4007\t val 0.0136\tAcc (val): 70.2%\n",
      "5 loss train: 0.3764\t val 0.0136\tAcc (val): 70.2%\n",
      "6 loss train: 0.3829\t val 0.0135\tAcc (val): 70.2%\n",
      "7 loss train: 0.3697\t val 0.0135\tAcc (val): 70.2%\n",
      "8 loss train: 0.3817\t val 0.0134\tAcc (val): 70.2%\n",
      "9 loss train: 0.3718\t val 0.0134\tAcc (val): 71.4%\n",
      "10 loss train: 0.3814\t val 0.0133\tAcc (val): 75.0%\n",
      "EPOCH  6\n",
      "0 loss train: 0.3583\t val 0.0133\tAcc (val): 72.6%\n",
      "1 loss train: 0.3791\t val 0.0132\tAcc (val): 75.0%\n",
      "2 loss train: 0.3684\t val 0.0132\tAcc (val): 77.4%\n",
      "3 loss train: 0.3729\t val 0.0131\tAcc (val): 76.2%\n",
      "4 loss train: 0.3496\t val 0.0131\tAcc (val): 75.0%\n",
      "5 loss train: 0.3646\t val 0.0130\tAcc (val): 78.6%\n",
      "6 loss train: 0.3743\t val 0.0130\tAcc (val): 78.6%\n",
      "7 loss train: 0.3565\t val 0.0129\tAcc (val): 78.6%\n",
      "8 loss train: 0.3614\t val 0.0129\tAcc (val): 78.6%\n",
      "9 loss train: 0.3644\t val 0.0129\tAcc (val): 78.6%\n",
      "10 loss train: 0.3443\t val 0.0128\tAcc (val): 77.4%\n",
      "EPOCH  7\n",
      "0 loss train: 0.3540\t val 0.0128\tAcc (val): 78.6%\n",
      "1 loss train: 0.3583\t val 0.0127\tAcc (val): 81.0%\n",
      "2 loss train: 0.3417\t val 0.0127\tAcc (val): 81.0%\n",
      "3 loss train: 0.3608\t val 0.0126\tAcc (val): 83.3%\n",
      "4 loss train: 0.3451\t val 0.0126\tAcc (val): 83.3%\n",
      "5 loss train: 0.3364\t val 0.0125\tAcc (val): 81.0%\n",
      "6 loss train: 0.3413\t val 0.0125\tAcc (val): 82.1%\n",
      "7 loss train: 0.3290\t val 0.0124\tAcc (val): 79.8%\n",
      "8 loss train: 0.3274\t val 0.0124\tAcc (val): 82.1%\n",
      "9 loss train: 0.3756\t val 0.0123\tAcc (val): 82.1%\n",
      "10 loss train: 0.3358\t val 0.0123\tAcc (val): 83.3%\n",
      "EPOCH  8\n",
      "0 loss train: 0.3301\t val 0.0122\tAcc (val): 84.5%\n",
      "1 loss train: 0.3343\t val 0.0122\tAcc (val): 83.3%\n",
      "2 loss train: 0.3606\t val 0.0121\tAcc (val): 83.3%\n",
      "3 loss train: 0.3411\t val 0.0121\tAcc (val): 83.3%\n",
      "4 loss train: 0.3158\t val 0.0120\tAcc (val): 82.1%\n",
      "5 loss train: 0.3202\t val 0.0120\tAcc (val): 84.5%\n",
      "6 loss train: 0.3184\t val 0.0120\tAcc (val): 84.5%\n",
      "7 loss train: 0.3088\t val 0.0119\tAcc (val): 84.5%\n",
      "8 loss train: 0.3319\t val 0.0119\tAcc (val): 84.5%\n",
      "9 loss train: 0.3225\t val 0.0118\tAcc (val): 83.3%\n",
      "10 loss train: 0.3433\t val 0.0117\tAcc (val): 83.3%\n",
      "EPOCH  9\n",
      "0 loss train: 0.3152\t val 0.0117\tAcc (val): 84.5%\n",
      "1 loss train: 0.3085\t val 0.0116\tAcc (val): 85.7%\n",
      "2 loss train: 0.3178\t val 0.0116\tAcc (val): 85.7%\n",
      "3 loss train: 0.3125\t val 0.0115\tAcc (val): 85.7%\n",
      "4 loss train: 0.3038\t val 0.0115\tAcc (val): 85.7%\n",
      "5 loss train: 0.3175\t val 0.0115\tAcc (val): 85.7%\n",
      "6 loss train: 0.3266\t val 0.0115\tAcc (val): 83.3%\n",
      "7 loss train: 0.2930\t val 0.0114\tAcc (val): 83.3%\n",
      "8 loss train: 0.3087\t val 0.0114\tAcc (val): 85.7%\n",
      "9 loss train: 0.3132\t val 0.0113\tAcc (val): 84.5%\n",
      "10 loss train: 0.3415\t val 0.0113\tAcc (val): 84.5%\n",
      "Accuracy (test): 85.7%\n"
     ]
    }
   ],
   "source": [
    "# exemple avec mobilenet v2\n",
    "my_net = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V1')\n",
    "my_net.classifier[1] = nn.Linear(in_features=my_net.classifier[1].in_features, out_features=nb_classes, bias=True)\n",
    "my_net.to(device)\n",
    "\n",
    "# mise à jour de tous les paramètres\n",
    "params_to_update = my_net.parameters()\n",
    "\n",
    "# définition de la fonction de coût et de l'optimiseur \n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# entrainement\n",
    "print(\"Apprentissage avec fine-tuning\")\n",
    "my_net.train(True)\n",
    "torch.manual_seed(42)\n",
    "train_model(my_net, loader_train, dataset_val, optimizer, criterion, n_epochs=10)\n",
    "\n",
    "# évaluation des performances\n",
    "my_net.train(False)\n",
    "loss, accuracy = evaluate(my_net, dataset_test, criterion)\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour aller plus loin : quel pourcentage d'images comporte au moins 2 logos de marques différentes selon le modèle ? comment choisir des seuils de décision adaptés à chacune des classes ? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
