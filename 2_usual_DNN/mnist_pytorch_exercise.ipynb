{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apprentissage profond - TD n°2\n",
    "__________\n",
    "Architectures DNN classiques appliquées à la classification de chiffres avec MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# we use GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données et problème\n",
    "\n",
    "On réutilise le dataset MNIST déjà téléchargé au TD précédent. Cette fois-ci, on va charger les données avec le module `Dataloader` de pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:05<00:00, 1.69MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 346kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.36MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "my_data_path = './data'\n",
    "train_set = datasets.MNIST( my_data_path, train=True, transform=trans, download=True )\n",
    "test_set = datasets.MNIST( my_data_path, train=False, transform=trans, download=True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulter la [documentation PyTorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) à propos des modules `Dataset` et `Dataloader`.\n",
    "\n",
    "NB : en pratique, on pourra définir [son propre dataloader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) pour un cas d'utilisation donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training batch number: 600\n",
      "total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "\n",
    "\n",
    "print('total training batch number: {}'.format(len(train_loader)))\n",
    "print('total testing batch number: {}'.format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des images en utilisant le chargement des données avec `Dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKEhJREFUeJzt3X90TXe+//HXicoRlRw/IpKMIELp8qudaFP1I1REYqpVev3qrOJaVBtt1W2ZGEVr3EzpdNrOVb13epfoDz/KtJR1h+tnVIsZ1HUNNaHpxSWpZL7JiYQw8vn+YTm3RxKxI/FJ4vlYa6+V89n7vff7bHvlZe+zs4/LGGMEAMBtFmC7AQDAnYkAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAiBJateuncaPH1+t6ywtLVXXrl21YMECx7WXL19WVFSU3nvvvWrtCbUHAYRbkp6eLpfLJZfLpV27dpWZb4xRVFSUXC6XHn30Ub951+p+85vfVLjeffv2+cbmzZsnl8ul3Nxcv2XXr1+v+Ph4hYWFqXHjxmrfvr1GjhypjRs3SpL69+/v29aNpnnz5lXDHsGPrVixQqdOndLUqVP9xvfv36+kpCSFhIQoODhYiYmJOnjwoN8yDRs21PTp07VgwQJdvHjxNnaN24UAQrVo1KiRli9fXmY8IyNDp0+fltvtrrB20aJFKi4urtJ233zzTT322GNyuVxKTU3Vb3/7W40YMUKZmZlauXKlJOmXv/ylPvroI9/0wgsvSJJmzZrlNz58+PAq9YCKLVq0SKNHj5bH4/GNHThwQH369NF3332nuXPnas6cOcrMzFR8fLyOHTvmVz9hwgTl5uaWe2yhHjDALVi6dKmRZIYPH25CQ0PN5cuX/eZPmjTJxMbGmrZt25qf/exnfvMkmfvuu89IMr/5zW/KXe+f//xn39jcuXONJHPu3DljjDGXL182ISEhZtCgQeX2lpOTU+746tWrjSSzfft2p2+3Xmvbtq0ZN25cta3vwIEDRpLZsmWL3/iQIUNMs2bNTG5urm/szJkzpkmTJmb48OFl1vPoo4+avn37VltfqD04A0K1GDNmjPLy8rR582bf2KVLl7RmzRqNHTu2wrrevXvrkUce0cKFC3XhwgVH28zNzZXX61Xv3r3LnR8WFuZofZXZu3evkpKS5PF41LhxY8XHx+urr77yzT969KiCgoL09NNP+9Xt2rVLDRo00MyZM31j69at089+9jNFRkbK7XYrJiZG8+fP15UrV/xq+/fvr65du+rQoUOKj49X48aN1aFDB61Zs0bS1TPMuLg4BQUFqVOnTtqyZYtf/bXLlt9++61GjhypkJAQtWjRQi+++OJNXdbKz8/XtGnTFBUVJbfbrQ4dOuiNN95QaWlppbVr165VYGCg+vXr5zf+5ZdfKiEhQS1atPCNRUREKD4+Xhs2bND58+f9lh80aJB27dqlv/3tb5VuE3ULAYRq0a5dO/Xq1UsrVqzwjf3xj39UQUGBRo8efcPaefPmKScnR0uWLHG0zbCwMAUFBWn9+vU1/stp27Zt6tevn7xer+bOnat//ud/Vn5+vh555BH96U9/kiTde++9mj9/vj766CN98cUXkqSioiKNHz9enTt31uuvv+5bX3p6upo0aaLp06frnXfeUWxsrObMmaNf/OIXZbb9//7f/9Ojjz6quLg4LVy4UG63W6NHj9aqVas0evRoDRkyRL/+9a9VVFSkJ598UoWFhWXWMXLkSF28eFFpaWkaMmSI3n33XU2ePPmG77m4uFjx8fH6+OOP9fTTT+vdd99V7969lZqaqunTp1e6z77++mt17dpVDRs29BsvKSlRUFBQmeUbN26sS5cu6fDhw37jsbGxMsbo66+/rnSbqGNsn4KhbvvxpbJ/+Zd/McHBwaa4uNgYY8w//MM/mAEDBhhjTIWX4FJSUowxxgwYMMCEh4f7am/mEpwxxsyZM8dIMnfffbdJTk42CxYsMPv3779hz04vwZWWlpqOHTuawYMHm9LSUt94cXGxiY6O9rsEeOXKFdOnTx/TqlUrk5uba1JSUsxdd93l9z6u1V7vmWeeMY0bNzYXL170jcXHxxtJZvny5b6xb7/91kgyAQEBZs+ePb7xTZs2GUlm6dKlvrFr++yxxx7z29Zzzz1nJJn/+q//8o1dfwlu/vz55u677zZ//etf/Wp/8YtfmAYNGpiTJ09WtMuMMca0bt3ajBgxosx4t27dzD333GP+/ve/+8ZKSkpMmzZtjCSzZs0av+XPnDljJJk33njjhttD3cMZEKrNyJEjdeHCBW3YsEGFhYXasGHDDS+//di8efOUnZ2t999/39E2X3vtNS1fvlz333+/Nm3apF/+8peKjY3VT3/6Ux09erQqb6OMgwcPKjMzU2PHjlVeXp5yc3OVm5uroqIiDRw4UDt37vRdkgoICFB6errOnz+v5ORkvffee0pNTVXPnj391vnjM4DCwkLl5uaqb9++Ki4u1rfffuu3bJMmTfzOIjt16qSmTZvq3nvvVVxcnG/82s/fffddmfeQkpLi9/r555+XJP3Hf/xHhe979erV6tu3r5o1a+Z7z7m5uUpISNCVK1e0c+fOG+63vLw8NWvWrMz4c889p7/+9a+aOHGijhw5osOHD+vpp5/W2bNnJanMpdhr67j+7kfUfXfZbgD1R8uWLZWQkKDly5eruLhYV65c0ZNPPnlTtf369dOAAQO0cOFCTZkyxdF2x4wZozFjxsjr9Wrv3r1KT0/X8uXLNXToUB0+fFiNGjWqytvxyczMlCSNGzeuwmUKCgp8vyhjYmI0b948vfLKK+ratateffXVMsv/5S9/0ezZs7Vt2zZ5vd4y6/qx1q1by+Vy+Y15PB5FRUWVGZOuXrK7XseOHf1ex8TEKCAgQN9//32F7ykzM1OHDh1Sy5Yty53/ww8/VFh7jSnnC5enTJmiU6dOadGiRVq2bJkkqWfPnpoxY4YWLFigJk2alLuO6/cB6j4CCNVq7NixmjRpkrKzs5WcnKymTZvedO3cuXPVv39//eu//qujumtCQkI0aNAgDRo0SA0bNtSyZcu0d+9excfHO17Xj107u1m0aJHuu+++cpe5/pfmf/7nf0qSzpw5o7y8PIWHh/vm5efnKz4+XiEhIXr99dcVExOjRo0a6cCBA5o5c2aZD/gbNGhQ7jYrGi/vl/71buaXeWlpqQYNGqQZM2aUO/+ee+65YX2LFi3KDUNJWrBggV5++WX95S9/kcfjUbdu3TRr1qxy13ttHaGhoZX2jLqFAEK1euKJJ/TMM89oz549WrVqlaPa+Ph49e/fX2+88YbmzJlzS3307NlTy5Yt813WuRUxMTGSrgZcQkJCpcu///772rx5sxYsWKC0tDQ988wzWrdunW/+jh07lJeXp88++8zvDrGsrKxb7rUimZmZio6O9r0+fvy4SktL1a5duwprYmJidP78+Zt6z+Xp3LnzDd9Ts2bN1KdPH9/rLVu2qHXr1urcubPfctfWce+991apD9RefAaEatWkSRMtWbJE8+bN09ChQx3XX/ss6N/+7d8qXba4uFi7d+8ud94f//hHSVc/L7lVsbGxiomJ0ZtvvlnmFmFJOnfunO/nrKwsvfLKKxoxYoRmzZqlN998U1988YU+/PBD3zLXzlx+fKZy6dKlGn3kzOLFi/1e/+53v5MkJScnV1gzcuRI7d69W5s2bSozLz8/X3//+99vuM1evXrp8OHDKikpqbS/VatW6c9//rOmTZumgAD/X0v79++Xy+VSr169Kl0P6hbOgFDtbvRZSWXi4+MVHx+vjIyMSpctLi7Www8/rIceekhJSUmKiopSfn6+1q5dqy+//FLDhg3T/fffX+VergkICNAHH3yg5ORkdenSRRMmTNBPfvIT/e///q+2b9+ukJAQrV+/XsYY/eM//qOCgoJ8t5Q/88wz+sMf/qAXX3xRCQkJioyM1MMPP6xmzZpp3LhxeuGFF+RyufTRRx/d1KWzqsrKytJjjz2mpKQk7d69Wx9//LHGjh2rHj16VFjzyiuv6IsvvtCjjz6q8ePHKzY2VkVFRfrv//5vrVmzRt9///0NL4s9/vjjmj9/vjIyMpSYmOgb37lzp15//XUlJiaqRYsW2rNnj5YuXaqkpCS9+OKLZdazefNm9e7d2+/vhlBP2LwFD3VfebdLl6ey27B/bPv27UbSTT0J4fe//70ZNmyYadu2rXG73aZx48bm/vvvN4sWLTIlJSXl9lLVJyF88803Zvjw4aZFixbG7Xabtm3bmpEjR5qtW7caY4x55513jCTzhz/8wa/u5MmTJiQkxAwZMsQ39tVXX5mHHnrIBAUFmcjISDNjxgzfbdQ/7is+Pt506dKlTC/l7U9jyu7Ta/vsyJEj5sknnzTBwcGmWbNmZurUqebChQtl1nn9kxAKCwtNamqq6dChgwkMDDShoaHm4YcfNm+++aa5dOlSpfuse/fuZuLEiX5jx48fN4mJiSY0NNS43W7TuXNnk5aWVu6/V35+vgkMDDQffPBBpdtC3eMypgb/2wXAqnnz5um1117TuXPnrHyI/9FHHyklJUUnT56s0o0lb7/9thYuXKgTJ06U+8erqNv4DAhAjXnqqafUpk2bMp9B3YzLly/rrbfe0uzZswmfeorPgADUmICAgDKP1rlZDRs21MmTJ6u5I9QmnAEBAKzgMyAAgBWcAQEArCCAAABW1LqbEEpLS3XmzBkFBwfz8EEAqIOMMSosLFRkZGSZJ1v8WK0LoDNnzpR5yi8AoO45deqUWrduXeH8WncJLjg42HYLAIBqUNnv8xoLoMWLF6tdu3Zq1KiR4uLifF9bXBkuuwFA/VDZ7/MaCaBVq1Zp+vTpmjt3rg4cOKAePXpo8ODBN/UFVgCAO0RNPGDuwQcf9Hsg4pUrV0xkZKRJS0urtLagoMD3IEomJiYmpro7FRQU3PD3fbWfAV26dEn79+/3+xKrgIAAJSQklPvdLSUlJfJ6vX4TAKD+q/YAys3N1ZUrV9SqVSu/8VatWik7O7vM8mlpafJ4PL6JO+AA4M5g/S641NRUFRQU+KZTp07ZbgkAcBtU+98BhYaGqkGDBsrJyfEbz8nJUXh4eJnl3W633G53dbcBAKjlqv0MKDAwULGxsdq6datvrLS0VFu3buU73QEAPjXyJITp06dr3Lhx6tmzpx588EG9/fbbKioq0oQJE2picwCAOqhGAmjUqFE6d+6c5syZo+zsbN13333auHFjmRsTAAB3rlr3fUBer1cej8d2GwCAW1RQUKCQkJAK51u/Cw4AcGcigAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsKLaA2jevHlyuVx+U+fOnat7MwCAOu6umlhply5dtGXLlv/byF01shkAQB1WI8lw1113KTw8vCZWDQCoJ2rkM6DMzExFRkaqffv2euqpp3Ty5MkKly0pKZHX6/WbAAD1X7UHUFxcnNLT07Vx40YtWbJEWVlZ6tu3rwoLC8tdPi0tTR6PxzdFRUVVd0sAgFrIZYwxNbmB/Px8tW3bVm+99ZYmTpxYZn5JSYlKSkp8r71eLyEEAPVAQUGBQkJCKpxf43cHNG3aVPfcc4+OHz9e7ny32y23213TbQAAapka/zug8+fP68SJE4qIiKjpTQEA6pBqD6CXX35ZGRkZ+v777/X111/riSeeUIMGDTRmzJjq3hQAoA6r9ktwp0+f1pgxY5SXl6eWLVuqT58+2rNnj1q2bFndmwIA1GE1fhOCU16vVx6Px3YbAIBbVNlNCDwLDgBgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsqPEvpAPqkri4OMc1P//5zx3XxMfHO67p0qWL45qqevnllx3XnDlzxnFNnz59HNd8/PHHjmv27t3ruAY1jzMgAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWMHTsFEvjRo1qkp177zzjuOa0NBQxzUul8txzY4dOxzXtGzZ0nGNJC1atKhKdU5VZT9U5T2NHj3acQ1qHmdAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFDyPFbXXXXc4PuZ49ezqu+f3vf++4RpIaN27suGbnzp2Oa+bPn++4ZteuXY5r3G634xpJ+vTTTx3XJCYmVmlbTu3bt++2bAc1jzMgAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCh5Hitvr5z3/uuOaDDz6ogU7Kt3nzZsc1o0aNclzj9Xod11RFVXqTbt+DRU+fPu24ZtmyZTXQCWzgDAgAYAUBBACwwnEA7dy5U0OHDlVkZKRcLpfWrl3rN98Yozlz5igiIkJBQUFKSEhQZmZmdfULAKgnHAdQUVGRevToocWLF5c7f+HChXr33Xf1/vvva+/evbr77rs1ePBgXbx48ZabBQDUH45vQkhOTlZycnK584wxevvttzV79mw9/vjjkqQPP/xQrVq10tq1azV69Ohb6xYAUG9U62dAWVlZys7OVkJCgm/M4/EoLi5Ou3fvLrempKREXq/XbwIA1H/VGkDZ2dmSpFatWvmNt2rVyjfvemlpafJ4PL4pKiqqOlsCANRS1u+CS01NVUFBgW86deqU7ZYAALdBtQZQeHi4JCknJ8dvPCcnxzfvem63WyEhIX4TAKD+q9YAio6OVnh4uLZu3eob83q92rt3r3r16lWdmwIA1HGO74I7f/68jh8/7nudlZWlgwcPqnnz5mrTpo2mTZumX/3qV+rYsaOio6P16quvKjIyUsOGDavOvgEAdZzjANq3b58GDBjgez19+nRJ0rhx45Senq4ZM2aoqKhIkydPVn5+vvr06aONGzeqUaNG1dc1AKDOcxljjO0mfszr9crj8dhuAzdh/vz5jmtmzZrluKYqh+h7773nuEaSZs+e7bimNv/pwNGjR6tU17Fjx2rupHwjRoxwXLNu3boa6AQ1oaCg4Iaf61u/Cw4AcGcigAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACsdfx4D6Z86cOVWqq8qTrS9duuS4ZtOmTY5rZs6c6bhGki5cuFClOqeq8vUkiYmJjmvatGnjuEaSXC6X45pf/epXjmt4svWdjTMgAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCh5HWM02bNnVc89xzz1VpW8YYxzVVebDosGHDHNfcTh06dHBc88knnziuiY2NdVxTVWvWrHFcs3DhwhroBPUZZ0AAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUPI61nAgMDHdeEhobWQCfle+GFFxzXhIWFOa6ZMGGC4xpJeuyxxxzXdO3a1XFNkyZNHNdU5eGvVamRpI8//thxTVFRUZW2hTsXZ0AAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYIXLVPVphTXE6/XK4/HYbqPOatq0qeOao0ePVmlbLVu2dFzjcrkc19SyQ7SMM2fOOK6pyn6IiIhwXHPu3DnHNVXdFnC9goIChYSEVDifMyAAgBUEEADACscBtHPnTg0dOlSRkZFyuVxau3at3/zx48fL5XL5TUlJSdXVLwCgnnAcQEVFRerRo4cWL15c4TJJSUk6e/asb1qxYsUtNQkAqH8cfyNqcnKykpOTb7iM2+1WeHh4lZsCANR/NfIZ0I4dOxQWFqZOnTrp2WefVV5eXoXLlpSUyOv1+k0AgPqv2gMoKSlJH374obZu3ao33nhDGRkZSk5O1pUrV8pdPi0tTR6PxzdFRUVVd0sAgFrI8SW4yowePdr3c7du3dS9e3fFxMRox44dGjhwYJnlU1NTNX36dN9rr9dLCAHAHaDGb8Nu3769QkNDdfz48XLnu91uhYSE+E0AgPqvxgPo9OnTysvL4y+rAQB+HF+CO3/+vN/ZTFZWlg4ePKjmzZurefPmeu211zRixAiFh4frxIkTmjFjhjp06KDBgwdXa+MAgLrNcQDt27dPAwYM8L2+9vnNuHHjtGTJEh06dEjLli1Tfn6+IiMjlZiYqPnz58vtdldf1wCAOs9xAPXv3/+GD4fctGnTLTWEW5Ofn++4ZtiwYVXa1oYNGxzXNG/e3HHNiRMnHNesW7fOcY0kpaenO67529/+5rhm5cqVjmuqchm7KtsBbheeBQcAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArqv0ruVH37N27t0p1LVu2rOZO6qZ+/fo5romPj3dcU1pa6rjmu+++c1wD3C6cAQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFTyMFLhFQUFBjmuq8mBRY4zjmpUrVzquAW4XzoAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoeRgrcok2bNtluAaiTOAMCAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACt4GClwiwYPHmy7BaBO4gwIAGAFAQQAsMJRAKWlpemBBx5QcHCwwsLCNGzYMB07dsxvmYsXLyolJUUtWrRQkyZNNGLECOXk5FRr0wCAus9RAGVkZCglJUV79uzR5s2bdfnyZSUmJqqoqMi3zEsvvaT169dr9erVysjI0JkzZzR8+PBqbxwAULc5uglh48aNfq/T09MVFham/fv3q1+/fiooKNC///u/a/ny5XrkkUckSUuXLtW9996rPXv26KGHHqq+zgEAddotfQZUUFAgSWrevLkkaf/+/bp8+bISEhJ8y3Tu3Flt2rTR7t27y11HSUmJvF6v3wQAqP+qHEClpaWaNm2aevfura5du0qSsrOzFRgYqKZNm/ot26pVK2VnZ5e7nrS0NHk8Ht8UFRVV1ZYAAHVIlQMoJSVFhw8f1sqVK2+pgdTUVBUUFPimU6dO3dL6AAB1Q5X+EHXq1KnasGGDdu7cqdatW/vGw8PDdenSJeXn5/udBeXk5Cg8PLzcdbndbrnd7qq0AQCowxydARljNHXqVH3++efatm2boqOj/ebHxsaqYcOG2rp1q2/s2LFjOnnypHr16lU9HQMA6gVHZ0ApKSlavny51q1bp+DgYN/nOh6PR0FBQfJ4PJo4caKmT5+u5s2bKyQkRM8//7x69erFHXAAAD+OAmjJkiWSpP79+/uNL126VOPHj5ck/fa3v1VAQIBGjBihkpISDR48WO+99161NAsAqD8cBZAxptJlGjVqpMWLF2vx4sVVbgqoS9q3b2+7BaBO4llwAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsKJK34gK4P98+eWXjmsCApz/36+0tNRxDVCbcQYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFbwMFLgFh0+fNhxTWZmpuOa9u3bO66JiYlxXCNJ586dq1Id4ARnQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABghcsYY2w38WNer1cej8d2G0CNGj9+vOOaDz74wHFNRkaG4xpJev755x3XHDlypErbQv1VUFCgkJCQCudzBgQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVvAwUsCCGz2gsSKffvqp45qEhATHNZL02WefOa6ZMGGC45qioiLHNag7eBgpAKBWIoAAAFY4CqC0tDQ98MADCg4OVlhYmIYNG6Zjx475LdO/f3+5XC6/acqUKdXaNACg7nMUQBkZGUpJSdGePXu0efNmXb58WYmJiWWu406aNElnz571TQsXLqzWpgEAdd9dThbeuHGj3+v09HSFhYVp//796tevn2+8cePGCg8Pr54OAQD10i19BlRQUCBJat68ud/4J598otDQUHXt2lWpqakqLi6ucB0lJSXyer1+EwCg/nN0BvRjpaWlmjZtmnr37q2uXbv6xseOHau2bdsqMjJShw4d0syZM3Xs2LEKb+tMS0vTa6+9VtU2AAB1VJUDKCUlRYcPH9auXbv8xidPnuz7uVu3boqIiNDAgQN14sQJxcTElFlPamqqpk+f7nvt9XoVFRVV1bYAAHVElQJo6tSp2rBhg3bu3KnWrVvfcNm4uDhJ0vHjx8sNILfbLbfbXZU2AAB1mKMAMsbo+eef1+eff64dO3YoOjq60pqDBw9KkiIiIqrUIACgfnIUQCkpKVq+fLnWrVun4OBgZWdnS5I8Ho+CgoJ04sQJLV++XEOGDFGLFi106NAhvfTSS+rXr5+6d+9eI28AAFA3OQqgJUuWSLr6x6Y/tnTpUo0fP16BgYHasmWL3n77bRUVFSkqKkojRozQ7Nmzq61hAED94PgS3I1ERUUpIyPjlhoCANwZeBo2UEdU5QnaCxYsqNK2nn32Wcc1VbnMfuTIEcc1qDt4GjYAoFYigAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBU8jBQAUCN4GCkAoFYigAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAAral0A1bJH0wEAqqiy3+e1LoAKCwtttwAAqAaV/T6vdU/DLi0t1ZkzZxQcHCyXy+U3z+v1KioqSqdOnbrhE1brO/bDVeyHq9gPV7EfrqoN+8EYo8LCQkVGRiogoOLznLtuY083JSAgQK1bt77hMiEhIXf0AXYN++Eq9sNV7Ier2A9X2d4PN/O1OrXuEhwA4M5AAAEArKhTAeR2uzV37ly53W7brVjFfriK/XAV++Eq9sNVdWk/1LqbEAAAd4Y6dQYEAKg/CCAAgBUEEADACgIIAGAFAQQAsKLOBNDixYvVrl07NWrUSHFxcfrTn/5ku6Xbbt68eXK5XH5T586dbbdV43bu3KmhQ4cqMjJSLpdLa9eu9ZtvjNGcOXMUERGhoKAgJSQkKDMz006zNaiy/TB+/Pgyx0dSUpKdZmtIWlqaHnjgAQUHByssLEzDhg3TsWPH/Ja5ePGiUlJS1KJFCzVp0kQjRoxQTk6OpY5rxs3sh/79+5c5HqZMmWKp4/LViQBatWqVpk+frrlz5+rAgQPq0aOHBg8erB9++MF2a7ddly5ddPbsWd+0a9cu2y3VuKKiIvXo0UOLFy8ud/7ChQv17rvv6v3339fevXt19913a/Dgwbp48eJt7rRmVbYfJCkpKcnv+FixYsVt7LDmZWRkKCUlRXv27NHmzZt1+fJlJSYmqqioyLfMSy+9pPXr12v16tXKyMjQmTNnNHz4cItdV7+b2Q+SNGnSJL/jYeHChZY6roCpAx588EGTkpLie33lyhUTGRlp0tLSLHZ1+82dO9f06NHDdhtWSTKff/6573VpaakJDw83ixYt8o3l5+cbt9ttVqxYYaHD2+P6/WCMMePGjTOPP/64lX5s+eGHH4wkk5GRYYy5+m/fsGFDs3r1at8yR48eNZLM7t27bbVZ467fD8YYEx8fb1588UV7Td2EWn8GdOnSJe3fv18JCQm+sYCAACUkJGj37t0WO7MjMzNTkZGRat++vZ566imdPHnSdktWZWVlKTs72+/48Hg8iouLuyOPjx07digsLEydOnXSs88+q7y8PNst1aiCggJJUvPmzSVJ+/fv1+XLl/2Oh86dO6tNmzb1+ni4fj9c88knnyg0NFRdu3ZVamqqiouLbbRXoVr3NOzr5ebm6sqVK2rVqpXfeKtWrfTtt99a6sqOuLg4paenq1OnTjp79qxee+019e3bV4cPH1ZwcLDt9qzIzs6WpHKPj2vz7hRJSUkaPny4oqOjdeLECc2aNUvJycnavXu3GjRoYLu9aldaWqpp06apd+/e6tq1q6Srx0NgYKCaNm3qt2x9Ph7K2w+SNHbsWLVt21aRkZE6dOiQZs6cqWPHjumzzz6z2K2/Wh9A+D/Jycm+n7t37664uDi1bdtWn376qSZOnGixM9QGo0eP9v3crVs3de/eXTExMdqxY4cGDhxosbOakZKSosOHD98Rn4PeSEX7YfLkyb6fu3XrpoiICA0cOFAnTpxQTEzM7W6zXLX+ElxoaKgaNGhQ5i6WnJwchYeHW+qqdmjatKnuueceHT9+3HYr1lw7Bjg+ymrfvr1CQ0Pr5fExdepUbdiwQdu3b/f7/rDw8HBdunRJ+fn5fsvX1+Ohov1Qnri4OEmqVcdDrQ+gwMBAxcbGauvWrb6x0tJSbd26Vb169bLYmX3nz5/XiRMnFBERYbsVa6KjoxUeHu53fHi9Xu3du/eOPz5Onz6tvLy8enV8GGM0depUff7559q2bZuio6P95sfGxqphw4Z+x8OxY8d08uTJenU8VLYfynPw4EFJql3Hg+27IG7GypUrjdvtNunp6ebIkSNm8uTJpmnTpiY7O9t2a7fVP/3TP5kdO3aYrKws89VXX5mEhAQTGhpqfvjhB9ut1ajCwkLzzTffmG+++cZIMm+99Zb55ptvzP/8z/8YY4z59a9/bZo2bWrWrVtnDh06ZB5//HETHR1tLly4YLnz6nWj/VBYWGhefvlls3v3bpOVlWW2bNlifvrTn5qOHTuaixcv2m692jz77LPG4/GYHTt2mLNnz/qm4uJi3zJTpkwxbdq0Mdu2bTP79u0zvXr1Mr169bLYdfWrbD8cP37cvP7662bfvn0mKyvLrFu3zrRv397069fPcuf+6kQAGWPM7373O9OmTRsTGBhoHnzwQbNnzx7bLd12o0aNMhERESYwMND85Cc/MaNGjTLHjx+33VaN2759u5FUZho3bpwx5uqt2K+++qpp1aqVcbvdZuDAgebYsWN2m64BN9oPxcXFJjEx0bRs2dI0bNjQtG3b1kyaNKne/SetvPcvySxdutS3zIULF8xzzz1nmjVrZho3bmyeeOIJc/bsWXtN14DK9sPJkydNv379TPPmzY3b7TYdOnQwr7zyiikoKLDb+HX4PiAAgBW1/jMgAED9RAABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVvx/rFAuJfBEe3EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display some images\n",
    "# for an alternative see https://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
    "def imshow(tensor, title=None):\n",
    "    img = tensor.cpu().clone()\n",
    "    img = img.squeeze()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.5)\n",
    "\n",
    "plt.figure()\n",
    "for ii in range(5):\n",
    "    imshow(train_set.data[ii] , title='MNIST example ({})'.format(train_set.targets[ii]) )\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modélisation MLP\n",
    "\n",
    "On commence par définir les tailles d'entrée et de sortie du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition des tailles d'entrée et de sortie\n",
    "DATA_SIZE = 784 # 28 * 28 pixels\n",
    "NUM_CLASSES = 10 # 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Régression softmax__\n",
    "\n",
    "Implémentation d'une classe `RegSoftNet` pour apprendre un modèle de régression softmax (généralisation à >  2 classesde la régression logistique).\n",
    "\n",
    "Ici on utilise simplement 1 couche cachée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegSoftNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegSoftNet, self).__init__()\n",
    "        self.fc = nn.Linear(DATA_SIZE,NUM_CLASSES)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, DATA_SIZE) # passer de 28*28 à  (784,)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegSoftNet()\n",
    "model.to(device) # pour faire passer le modèle sur GPU / CPU\n",
    "\n",
    "# optimization hyperparameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05) # try lr=0.01, momentum=0.9\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : Utilisation de model.train(), model.eval(), et with torch.no_grad()\n",
    "* model.train() active les couches de type \"dropout\" ou \"batchnorm\". __Par défaut, tous les modules sont initialisés avec `train = True`__.\n",
    "* model.eval() désactive la mise à jour des couches de type \"dropout\" ou \"batchnorm\".\n",
    "* with torch.no_grad() économise de la mémoire et du temps de calcul au moment de l'inférence, dans la mesure où cela désactive la stockage des valeurs intermédiaires dans le graphe de calcul. Conserver en mémoire ces valeurs intermédiaires est utile pour effectuer la rétropropagation, mais inutile à l'inférence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 [0/60000] training loss: 2.302354097366333\n",
      "epoch 0 batch 100 [10000/60000] training loss: 0.7085167169570923\n",
      "epoch 0 batch 200 [20000/60000] training loss: 0.35098689794540405\n",
      "epoch 0 batch 300 [30000/60000] training loss: 0.2305903434753418\n",
      "epoch 0 batch 400 [40000/60000] training loss: 0.22082661092281342\n",
      "epoch 0 batch 500 [50000/60000] training loss: 0.3764210045337677\n",
      "Test Accuracy: 9151/10000 (tx 91.51%, err 8.49%)\n",
      "\n",
      "tensor([[      961.,         0.,         9.,         3.,         1.,         9.,\n",
      "                13.,         2.,         9.,        11.],\n",
      "        [        0.,      1108.,         7.,         1.,         4.,         3.,\n",
      "                 3.,        12.,         9.,         7.],\n",
      "        [        3.,         3.,       925.,        25.,         3.,         4.,\n",
      "                 5.,        26.,        10.,         3.],\n",
      "        [        2.,         2.,        12.,       885.,         0.,        23.,\n",
      "                 2.,         4.,        13.,         9.],\n",
      "        [        0.,         0.,        17.,         1.,       923.,        12.,\n",
      "                27.,        11.,        11.,        45.],\n",
      "        [        7.,         2.,         5.,        51.,         2.,       790.,\n",
      "                28.,         0.,        40.,         8.],\n",
      "        [        4.,         4.,        10.,         2.,         8.,        13.,\n",
      "               876.,         0.,         7.,         0.],\n",
      "        [        1.,         2.,        13.,        13.,         2.,         7.,\n",
      "                 2.,       944.,        13.,        28.],\n",
      "        [        2.,        14.,        26.,        16.,         6.,        21.,\n",
      "                 2.,         2.,       851.,        10.],\n",
      "        [        0.,         0.,         8.,        13.,        33.,        10.,\n",
      "                 0.,        27.,        11.,       888.]])\n",
      "epoch 1 batch 0 [0/60000] training loss: 0.37952208518981934\n",
      "epoch 1 batch 100 [10000/60000] training loss: 0.293964147567749\n",
      "epoch 1 batch 200 [20000/60000] training loss: 0.3417675793170929\n",
      "epoch 1 batch 300 [30000/60000] training loss: 0.27658140659332275\n",
      "epoch 1 batch 400 [40000/60000] training loss: 0.3915553390979767\n",
      "epoch 1 batch 500 [50000/60000] training loss: 0.2973223328590393\n",
      "Test Accuracy: 9186/10000 (tx 91.86%, err 8.14%)\n",
      "\n",
      "tensor([[      957.,         0.,        10.,         3.,         1.,        12.,\n",
      "                11.,         1.,         8.,        10.],\n",
      "        [        0.,      1109.,        11.,         1.,         5.,         3.,\n",
      "                 3.,        15.,         9.,        11.],\n",
      "        [        3.,         3.,       918.,        25.,         3.,         1.,\n",
      "                 4.,        24.,         5.,         1.],\n",
      "        [        1.,         2.,        12.,       902.,         1.,        34.,\n",
      "                 2.,         9.,        15.,        10.],\n",
      "        [        0.,         0.,        15.,         0.,       908.,         8.,\n",
      "                10.,        10.,         8.,        31.],\n",
      "        [        6.,         1.,         2.,        28.,         0.,       757.,\n",
      "                 9.,         1.,        18.,         7.],\n",
      "        [        9.,         4.,        14.,         3.,        13.,        18.,\n",
      "               914.,         0.,        10.,         1.],\n",
      "        [        2.,         2.,         8.,        11.,         2.,         8.,\n",
      "                 1.,       937.,        10.,        25.],\n",
      "        [        2.,        14.,        36.,        32.,        12.,        45.,\n",
      "                 4.,         2.,       890.,        19.],\n",
      "        [        0.,         0.,         6.,         5.,        37.,         6.,\n",
      "                 0.,        29.,         1.,       894.]])\n",
      "epoch 2 batch 0 [0/60000] training loss: 0.31063956022262573\n",
      "epoch 2 batch 100 [10000/60000] training loss: 0.2551923990249634\n",
      "epoch 2 batch 200 [20000/60000] training loss: 0.35383501648902893\n",
      "epoch 2 batch 300 [30000/60000] training loss: 0.1784256547689438\n",
      "epoch 2 batch 400 [40000/60000] training loss: 0.2608502507209778\n",
      "epoch 2 batch 500 [50000/60000] training loss: 0.27616196870803833\n",
      "Test Accuracy: 9184/10000 (tx 91.84%, err 8.16%)\n",
      "\n",
      "tensor([[      968.,         0.,        11.,         4.,         1.,        11.,\n",
      "                14.,         2.,        12.,        11.],\n",
      "        [        0.,      1114.,        14.,         1.,         2.,         4.,\n",
      "                 3.,         9.,        12.,         7.],\n",
      "        [        0.,         2.,       898.,        12.,         2.,         1.,\n",
      "                 2.,        18.,         5.,         1.],\n",
      "        [        2.,         2.,        19.,       932.,         1.,        42.,\n",
      "                 2.,         8.,        29.,        10.],\n",
      "        [        0.,         0.,        11.,         0.,       919.,        11.,\n",
      "                10.,         9.,        10.,        36.],\n",
      "        [        2.,         2.,         3.,        20.,         1.,       759.,\n",
      "                11.,         1.,        32.,         5.],\n",
      "        [        6.,         4.,        13.,         4.,        12.,        20.,\n",
      "               913.,         0.,        13.,         1.],\n",
      "        [        1.,         2.,        16.,        12.,         3.,         8.,\n",
      "                 2.,       943.,        12.,        22.],\n",
      "        [        1.,         9.,        37.,        12.,         3.,        26.,\n",
      "                 1.,         1.,       827.,         5.],\n",
      "        [        0.,         0.,        10.,        13.,        38.,        10.,\n",
      "                 0.,        37.,        22.,       911.]])\n",
      "epoch 3 batch 0 [0/60000] training loss: 0.40775740146636963\n",
      "epoch 3 batch 100 [10000/60000] training loss: 0.32766854763031006\n",
      "epoch 3 batch 200 [20000/60000] training loss: 0.36912041902542114\n",
      "epoch 3 batch 300 [30000/60000] training loss: 0.14669981598854065\n",
      "epoch 3 batch 400 [40000/60000] training loss: 0.4224610924720764\n",
      "epoch 3 batch 500 [50000/60000] training loss: 0.31823229789733887\n",
      "Test Accuracy: 9233/10000 (tx 92.33%, err 7.67%)\n",
      "\n",
      "tensor([[      962.,         0.,         7.,         3.,         1.,         9.,\n",
      "                11.,         1.,         7.,        10.],\n",
      "        [        0.,      1110.,         8.,         1.,         4.,         3.,\n",
      "                 3.,         9.,         6.,         7.],\n",
      "        [        2.,         2.,       923.,        21.,         3.,         2.,\n",
      "                 3.,        22.,         7.,         1.],\n",
      "        [        2.,         2.,        11.,       914.,         1.,        32.,\n",
      "                 2.,         8.,        24.,        13.],\n",
      "        [        0.,         0.,         9.,         0.,       912.,        11.,\n",
      "                10.,         6.,         9.,        31.],\n",
      "        [        2.,         1.,         6.,        25.,         0.,       768.,\n",
      "                10.,         1.,        20.,         7.],\n",
      "        [        9.,         4.,        11.,         4.,        13.,        17.,\n",
      "               913.,         0.,        10.,         1.],\n",
      "        [        2.,         2.,        13.,        15.,         5.,        10.,\n",
      "                 3.,       956.,        10.,        32.],\n",
      "        [        1.,        14.,        35.,        20.,         8.,        34.,\n",
      "                 3.,         3.,       876.,         8.],\n",
      "        [        0.,         0.,         9.,         7.,        35.,         6.,\n",
      "                 0.,        22.,         5.,       899.]])\n",
      "epoch 4 batch 0 [0/60000] training loss: 0.21377800405025482\n",
      "epoch 4 batch 100 [10000/60000] training loss: 0.2916947305202484\n",
      "epoch 4 batch 200 [20000/60000] training loss: 0.25262439250946045\n",
      "epoch 4 batch 300 [30000/60000] training loss: 0.33675429224967957\n",
      "epoch 4 batch 400 [40000/60000] training loss: 0.21481141448020935\n",
      "epoch 4 batch 500 [50000/60000] training loss: 0.1938483566045761\n",
      "Test Accuracy: 9238/10000 (tx 92.38%, err 7.62%)\n",
      "\n",
      "tensor([[      961.,         0.,         5.,         3.,         1.,         9.,\n",
      "                10.,         2.,         9.,         9.],\n",
      "        [        0.,      1109.,         9.,         1.,         2.,         3.,\n",
      "                 3.,         7.,         7.,         6.],\n",
      "        [        2.,         3.,       928.,        21.,         4.,         3.,\n",
      "                 2.,        25.,         7.,         2.],\n",
      "        [        2.,         2.,        16.,       929.,         1.,        36.,\n",
      "                 2.,        10.,        31.,        13.],\n",
      "        [        0.,         0.,         9.,         1.,       922.,        12.,\n",
      "                 9.,         8.,        11.,        34.],\n",
      "        [        3.,         1.,         5.,        20.,         0.,       769.,\n",
      "                11.,         1.,        23.,         5.],\n",
      "        [        9.,         4.,        12.,         2.,        12.,        18.,\n",
      "               916.,         0.,        12.,         0.],\n",
      "        [        2.,         2.,        11.,         8.,         2.,         7.,\n",
      "                 3.,       940.,         7.,        22.],\n",
      "        [        1.,        14.,        29.,        17.,         5.,        28.,\n",
      "                 2.,         2.,       856.,        10.],\n",
      "        [        0.,         0.,         8.,         8.,        33.,         7.,\n",
      "                 0.,        33.,        11.,       908.]])\n",
      "epoch 5 batch 0 [0/60000] training loss: 0.46333393454551697\n",
      "epoch 5 batch 100 [10000/60000] training loss: 0.20484046638011932\n",
      "epoch 5 batch 200 [20000/60000] training loss: 0.19498690962791443\n",
      "epoch 5 batch 300 [30000/60000] training loss: 0.21357057988643646\n",
      "epoch 5 batch 400 [40000/60000] training loss: 0.22758625447750092\n",
      "epoch 5 batch 500 [50000/60000] training loss: 0.27410441637039185\n",
      "Test Accuracy: 9244/10000 (tx 92.44%, err 7.56%)\n",
      "\n",
      "tensor([[      966.,         0.,         7.,         3.,         2.,        10.,\n",
      "                12.,         4.,         5.,        10.],\n",
      "        [        0.,      1110.,         8.,         0.,         2.,         2.,\n",
      "                 3.,         6.,         7.,         7.],\n",
      "        [        2.,         3.,       923.,        23.,         3.,         3.,\n",
      "                 6.,        23.,         6.,         1.],\n",
      "        [        2.,         2.,        15.,       917.,         1.,        38.,\n",
      "                 2.,         6.,        21.,        10.],\n",
      "        [        0.,         0.,        10.,         0.,       912.,        11.,\n",
      "                10.,         7.,         8.,        23.],\n",
      "        [        2.,         1.,         5.,        18.,         0.,       755.,\n",
      "                11.,         1.,        15.,         6.],\n",
      "        [        6.,         3.,         9.,         3.,        13.,        14.,\n",
      "               909.,         0.,         7.,         0.],\n",
      "        [        1.,         2.,        12.,        14.,         5.,         7.,\n",
      "                 2.,       951.,         9.,        27.],\n",
      "        [        1.,        14.,        37.,        24.,         7.,        47.,\n",
      "                 3.,         3.,       887.,        11.],\n",
      "        [        0.,         0.,         6.,         8.,        37.,         5.,\n",
      "                 0.,        27.,         9.,       914.]])\n",
      "epoch 6 batch 0 [0/60000] training loss: 0.2755115032196045\n",
      "epoch 6 batch 100 [10000/60000] training loss: 0.3603910803794861\n",
      "epoch 6 batch 200 [20000/60000] training loss: 0.2460929900407791\n",
      "epoch 6 batch 300 [30000/60000] training loss: 0.2132667601108551\n",
      "epoch 6 batch 400 [40000/60000] training loss: 0.1502140760421753\n",
      "epoch 6 batch 500 [50000/60000] training loss: 0.19437772035598755\n",
      "Test Accuracy: 9239/10000 (tx 92.39%, err 7.61%)\n",
      "\n",
      "tensor([[      961.,         0.,         5.,         3.,         1.,         9.,\n",
      "                10.,         1.,         5.,         9.],\n",
      "        [        0.,      1109.,         9.,         0.,         2.,         2.,\n",
      "                 3.,         7.,         9.,         8.],\n",
      "        [        2.,         4.,       934.,        23.,         4.,         2.,\n",
      "                 4.,        23.,         9.,         2.],\n",
      "        [        2.,         2.,        13.,       920.,         1.,        37.,\n",
      "                 2.,         7.,        26.,         8.],\n",
      "        [        0.,         0.,         7.,         0.,       910.,        11.,\n",
      "                 8.,         7.,         8.,        26.],\n",
      "        [        2.,         2.,         4.,        24.,         0.,       770.,\n",
      "                11.,         1.,        25.,         7.],\n",
      "        [       10.,         4.,        12.,         4.,        15.,        17.,\n",
      "               915.,         0.,         9.,         0.],\n",
      "        [        2.,         2.,        11.,        11.,         5.,         7.,\n",
      "                 3.,       951.,        11.,        31.],\n",
      "        [        1.,        12.,        27.,        14.,         4.,        32.,\n",
      "                 2.,         2.,       860.,         9.],\n",
      "        [        0.,         0.,        10.,        11.,        40.,         5.,\n",
      "                 0.,        29.,        12.,       909.]])\n",
      "epoch 7 batch 0 [0/60000] training loss: 0.17839324474334717\n",
      "epoch 7 batch 100 [10000/60000] training loss: 0.27136194705963135\n",
      "epoch 7 batch 200 [20000/60000] training loss: 0.1466342806816101\n",
      "epoch 7 batch 300 [30000/60000] training loss: 0.21281026303768158\n",
      "epoch 7 batch 400 [40000/60000] training loss: 0.34983378648757935\n",
      "epoch 7 batch 500 [50000/60000] training loss: 0.22998028993606567\n",
      "Test Accuracy: 9257/10000 (tx 92.57%, err 7.43%)\n",
      "\n",
      "tensor([[      960.,         0.,         5.,         2.,         1.,         9.,\n",
      "                10.,         1.,         6.,        10.],\n",
      "        [        0.,      1102.,         6.,         0.,         2.,         2.,\n",
      "                 3.,         6.,         4.,         6.],\n",
      "        [        2.,         6.,       947.,        28.,         7.,         3.,\n",
      "                 5.,        27.,        11.,         1.],\n",
      "        [        3.,         2.,        12.,       912.,         0.,        33.,\n",
      "                 2.,         7.,        16.,        12.],\n",
      "        [        0.,         0.,        10.,         1.,       929.,        11.,\n",
      "                10.,        11.,         8.,        40.],\n",
      "        [        4.,         1.,         4.,        26.,         0.,       775.,\n",
      "                 9.,         1.,        24.,         7.],\n",
      "        [        8.,         4.,        11.,         4.,        11.,        17.,\n",
      "               913.,         0.,        11.,         0.],\n",
      "        [        2.,         2.,         8.,        10.,         2.,         6.,\n",
      "                 3.,       942.,         8.,        24.],\n",
      "        [        1.,        18.,        22.,        21.,         7.,        31.,\n",
      "                 3.,         3.,       878.,        10.],\n",
      "        [        0.,         0.,         7.,         6.,        23.,         5.,\n",
      "                 0.,        30.,         8.,       899.]])\n",
      "epoch 8 batch 0 [0/60000] training loss: 0.1418955773115158\n",
      "epoch 8 batch 100 [10000/60000] training loss: 0.19780497252941132\n",
      "epoch 8 batch 200 [20000/60000] training loss: 0.27235496044158936\n",
      "epoch 8 batch 300 [30000/60000] training loss: 0.169890895485878\n",
      "epoch 8 batch 400 [40000/60000] training loss: 0.43962547183036804\n",
      "epoch 8 batch 500 [50000/60000] training loss: 0.21122980117797852\n",
      "Test Accuracy: 9245/10000 (tx 92.45%, err 7.55%)\n",
      "\n",
      "tensor([[      958.,         0.,         5.,         4.,         1.,         8.,\n",
      "                10.,         1.,         4.,        10.],\n",
      "        [        0.,      1112.,         9.,         1.,         3.,         2.,\n",
      "                 3.,         6.,        10.,         8.],\n",
      "        [        2.,         2.,       938.,        20.,         3.,         2.,\n",
      "                 3.,        23.,         6.,         1.],\n",
      "        [        3.,         2.,         9.,       898.,         1.,        23.,\n",
      "                 2.,         7.,        18.,         7.],\n",
      "        [        0.,         0.,         9.,         0.,       927.,        12.,\n",
      "                 8.,         8.,         9.,        43.],\n",
      "        [        5.,         3.,         7.,        39.,         0.,       782.,\n",
      "                12.,         1.,        27.,         7.],\n",
      "        [        9.,         4.,        13.,         5.,        13.,        17.,\n",
      "               915.,         0.,        12.,         0.],\n",
      "        [        2.,         2.,        10.,        11.,         2.,         6.,\n",
      "                 3.,       947.,         9.,        23.],\n",
      "        [        1.,        10.,        23.,        19.,         5.,        33.,\n",
      "                 2.,         2.,       867.,         9.],\n",
      "        [        0.,         0.,         9.,        13.,        27.,         7.,\n",
      "                 0.,        33.,        12.,       901.]])\n",
      "epoch 9 batch 0 [0/60000] training loss: 0.14098243415355682\n",
      "epoch 9 batch 100 [10000/60000] training loss: 0.1860007643699646\n",
      "epoch 9 batch 200 [20000/60000] training loss: 0.1807020604610443\n",
      "epoch 9 batch 300 [30000/60000] training loss: 0.28420770168304443\n",
      "epoch 9 batch 400 [40000/60000] training loss: 0.09146422147750854\n",
      "epoch 9 batch 500 [50000/60000] training loss: 0.17193488776683807\n",
      "Test Accuracy: 9256/10000 (tx 92.56%, err 7.44%)\n",
      "\n",
      "tensor([[      954.,         0.,         5.,         4.,         1.,         8.,\n",
      "                 9.,         1.,         7.,         9.],\n",
      "        [        0.,      1108.,         7.,         1.,         2.,         1.,\n",
      "                 3.,         8.,         6.,         7.],\n",
      "        [        2.,         4.,       944.,        27.,         4.,         2.,\n",
      "                 3.,        25.,        11.,         1.],\n",
      "        [        3.,         2.,         7.,       904.,         2.,        22.,\n",
      "                 2.,         6.,        17.,         9.],\n",
      "        [        0.,         0.,         6.,         0.,       917.,        10.,\n",
      "                 8.,         7.,         8.,        27.],\n",
      "        [        9.,         3.,         9.,        36.,         0.,       800.,\n",
      "                13.,         2.,        42.,        17.],\n",
      "        [        9.,         4.,        14.,         3.,        14.,        16.,\n",
      "               915.,         0.,        12.,         0.],\n",
      "        [        2.,         2.,         8.,         9.,         5.,         2.,\n",
      "                 3.,       948.,         7.,        23.],\n",
      "        [        1.,        12.,        25.,        19.,         8.,        26.,\n",
      "                 2.,         1.,       856.,         6.],\n",
      "        [        0.,         0.,         7.,         7.,        29.,         5.,\n",
      "                 0.,        30.,         8.,       910.]])\n"
     ]
    }
   ],
   "source": [
    "# Entrainement et évaluation\n",
    "\n",
    "for epoch in range(10):\n",
    "    # training\n",
    "    model.train() \n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx %100 ==0:\n",
    "            print('epoch {} batch {} [{}/{}] training loss: {}'.format(epoch,batch_idx,batch_idx*len(x),\n",
    "                    len(train_loader.dataset),loss.item()))\n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        confusion = torch.zeros(NUM_CLASSES,NUM_CLASSES)\n",
    "        for batch_idx, (x, target) in enumerate(test_loader):\n",
    "            x, target = x.to(device), target.to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, target)\n",
    "            # _, prediction = torch.max(out.data, 1)\n",
    "            prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "            # since 'prediction' and 'target' may be on the GPU memory\n",
    "            # thus (i,j) are on the GPU as well. They must be transfered\n",
    "            # to the CPU, where 'confusion' has been allocated\n",
    "            for i,j in zip(prediction,target):\n",
    "                confusion[i.to(\"cpu\"),j.to(\"cpu\")] += 1\n",
    "    taux_classif = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test Accuracy: {}/{} (tx {:.2f}%, err {:.2f}%)\\n'.format(correct,\n",
    "     len(test_loader.dataset), taux_classif, 100.-taux_classif))\n",
    "    torch.set_printoptions(sci_mode=False)\n",
    "    print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Perceptron multi-couche__\n",
    "\n",
    "On utilise ici 2 couches cachées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_1 = 256\n",
    "NUM_HIDDEN_2 = 256\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(DATA_SIZE, NUM_HIDDEN_1)\n",
    "        self.fc2 = nn.Linear(NUM_HIDDEN_1, NUM_HIDDEN_2)\n",
    "        self.fc3 = nn.Linear(NUM_HIDDEN_2, NUM_CLASSES)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, DATA_SIZE) # reshape the tensor \n",
    "        x = x.view(-1, DATA_SIZE) # reshape the tensor \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPNet()\n",
    "model.to(device) # pour faire passer le modèle sur GPU / CPU\n",
    "\n",
    "# redéfinir l'optimiseur ! \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05) # try lr=0.01, momentum=0.9\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nouveau, on entraine le modèle et on affiche au fur et à mesure des \"epochs\" la matrice de confusion sur les données d'évaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 [0/60000] training loss: 2.31058669090271\n",
      "epoch 0 batch 100 [10000/60000] training loss: 0.44559428095817566\n",
      "epoch 0 batch 200 [20000/60000] training loss: 0.3031843602657318\n",
      "epoch 0 batch 300 [30000/60000] training loss: 0.5005157589912415\n",
      "epoch 0 batch 400 [40000/60000] training loss: 0.182505264878273\n",
      "epoch 0 batch 500 [50000/60000] training loss: 0.2934805154800415\n",
      "Test Accuracy: 9359/10000 (tx 93.59%, err 6.41%)\n",
      "\n",
      "tensor([[      964.,         0.,         9.,         2.,         1.,        10.,\n",
      "                11.,         2.,        11.,        12.],\n",
      "        [        0.,      1122.,         8.,         1.,         5.,         2.,\n",
      "                 3.,        11.,        12.,        12.],\n",
      "        [        1.,         2.,       963.,        21.,         5.,         5.,\n",
      "                 5.,        26.,         6.,         1.],\n",
      "        [        1.,         2.,         7.,       947.,         1.,        43.,\n",
      "                 0.,         5.,        24.,        10.],\n",
      "        [        0.,         0.,         8.,         0.,       924.,         4.,\n",
      "                 6.,         5.,         8.,        37.],\n",
      "        [        3.,         1.,         0.,         7.,         0.,       781.,\n",
      "                 7.,         0.,        12.,         6.],\n",
      "        [        9.,         3.,        13.,         2.,        18.,        17.,\n",
      "               921.,         0.,        14.,         1.],\n",
      "        [        1.,         1.,         9.,        13.,         3.,         5.,\n",
      "                 2.,       955.,        11.,        12.],\n",
      "        [        1.,         4.,        12.,        12.,         3.,        17.,\n",
      "                 3.,         1.,       868.,         4.],\n",
      "        [        0.,         0.,         3.,         5.,        22.,         8.,\n",
      "                 0.,        23.,         8.,       914.]])\n",
      "epoch 1 batch 0 [0/60000] training loss: 0.2503753900527954\n",
      "epoch 1 batch 100 [10000/60000] training loss: 0.12341958284378052\n",
      "epoch 1 batch 200 [20000/60000] training loss: 0.265472412109375\n",
      "epoch 1 batch 300 [30000/60000] training loss: 0.23441478610038757\n",
      "epoch 1 batch 400 [40000/60000] training loss: 0.20117008686065674\n",
      "epoch 1 batch 500 [50000/60000] training loss: 0.10561146587133408\n",
      "Test Accuracy: 9542/10000 (tx 95.42%, err 4.58%)\n",
      "\n",
      "tensor([[      965.,         0.,         9.,         2.,         1.,         8.,\n",
      "                 9.,         0.,         5.,         5.],\n",
      "        [        0.,      1111.,         3.,         0.,         0.,         2.,\n",
      "                 3.,         8.,         1.,         6.],\n",
      "        [        1.,         2.,       978.,        10.,         4.,         0.,\n",
      "                 1.,        14.,         1.,         1.],\n",
      "        [        0.,         2.,         4.,       950.,         0.,        12.,\n",
      "                 0.,         3.,        10.,         6.],\n",
      "        [        0.,         0.,         9.,         0.,       948.,         3.,\n",
      "                11.,         4.,         9.,        24.],\n",
      "        [        3.,         1.,         0.,         8.,         0.,       834.,\n",
      "                11.,         0.,         5.,         2.],\n",
      "        [        6.,         6.,         5.,         1.,         5.,         8.,\n",
      "               918.,         0.,        10.,         1.],\n",
      "        [        3.,         2.,        11.,        13.,         2.,         2.,\n",
      "                 0.,       976.,        12.,         6.],\n",
      "        [        2.,        11.,        12.,        21.,         2.,        16.,\n",
      "                 5.,         1.,       914.,        10.],\n",
      "        [        0.,         0.,         1.,         5.,        20.,         7.,\n",
      "                 0.,        22.,         7.,       948.]])\n",
      "epoch 2 batch 0 [0/60000] training loss: 0.252829372882843\n",
      "epoch 2 batch 100 [10000/60000] training loss: 0.0491994172334671\n",
      "epoch 2 batch 200 [20000/60000] training loss: 0.07716993987560272\n",
      "epoch 2 batch 300 [30000/60000] training loss: 0.0635170266032219\n",
      "epoch 2 batch 400 [40000/60000] training loss: 0.15728938579559326\n",
      "epoch 2 batch 500 [50000/60000] training loss: 0.0883304700255394\n",
      "Test Accuracy: 9653/10000 (tx 96.53%, err 3.47%)\n",
      "\n",
      "tensor([[      967.,         0.,         8.,         2.,         1.,         6.,\n",
      "                11.,         0.,         6.,         4.],\n",
      "        [        0.,      1112.,         1.,         0.,         0.,         1.,\n",
      "                 3.,         7.,         0.,         5.],\n",
      "        [        1.,         3.,       995.,         2.,         7.,         0.,\n",
      "                 1.,        10.,         1.,         1.],\n",
      "        [        1.,         2.,         6.,       984.,         0.,        12.,\n",
      "                 0.,         7.,        12.,         8.],\n",
      "        [        0.,         0.,         3.,         0.,       943.,         3.,\n",
      "                10.,         0.,         3.,        11.],\n",
      "        [        3.,         1.,         0.,         5.,         1.,       852.,\n",
      "                10.,         0.,         6.,         6.],\n",
      "        [        3.,         5.,         1.,         0.,         1.,         8.,\n",
      "               919.,         0.,         5.,         1.],\n",
      "        [        2.,         2.,         8.,         7.,         2.,         1.,\n",
      "                 0.,       987.,         8.,         6.],\n",
      "        [        2.,        10.,         9.,         8.,         2.,         5.,\n",
      "                 4.,         2.,       930.,         3.],\n",
      "        [        1.,         0.,         1.,         2.,        25.,         4.,\n",
      "                 0.,        15.,         3.,       964.]])\n",
      "epoch 3 batch 0 [0/60000] training loss: 0.09165582060813904\n",
      "epoch 3 batch 100 [10000/60000] training loss: 0.1776321530342102\n",
      "epoch 3 batch 200 [20000/60000] training loss: 0.08618702739477158\n",
      "epoch 3 batch 300 [30000/60000] training loss: 0.09941776096820831\n",
      "epoch 3 batch 400 [40000/60000] training loss: 0.04252828285098076\n",
      "epoch 3 batch 500 [50000/60000] training loss: 0.1121165081858635\n",
      "Test Accuracy: 9686/10000 (tx 96.86%, err 3.14%)\n",
      "\n",
      "tensor([[      967.,         0.,         7.,         1.,         3.,         3.,\n",
      "                 8.,         2.,         3.,         4.],\n",
      "        [        0.,      1118.,         1.,         0.,         0.,         1.,\n",
      "                 3.,         6.,         0.,         4.],\n",
      "        [        1.,         3.,      1007.,         3.,         4.,         0.,\n",
      "                 0.,        16.,         2.,         0.],\n",
      "        [        2.,         1.,         3.,       982.,         0.,         7.,\n",
      "                 2.,         3.,        13.,        11.],\n",
      "        [        0.,         0.,         1.,         0.,       952.,         2.,\n",
      "                 3.,         0.,         3.,        16.],\n",
      "        [        4.,         2.,         0.,        10.,         1.,       862.,\n",
      "                 5.,         0.,         7.,         9.],\n",
      "        [        3.,         4.,         3.,         0.,         7.,         8.,\n",
      "               932.,         0.,         8.,         2.],\n",
      "        [        2.,         1.,         7.,         7.,         2.,         1.,\n",
      "                 1.,       988.,         6.,         7.],\n",
      "        [        1.,         6.,         2.,         5.,         3.,         6.,\n",
      "                 4.,         2.,       930.,         8.],\n",
      "        [        0.,         0.,         1.,         2.,        10.,         2.,\n",
      "                 0.,        11.,         2.,       948.]])\n",
      "epoch 4 batch 0 [0/60000] training loss: 0.09644672274589539\n",
      "epoch 4 batch 100 [10000/60000] training loss: 0.0844796821475029\n",
      "epoch 4 batch 200 [20000/60000] training loss: 0.06939642131328583\n",
      "epoch 4 batch 300 [30000/60000] training loss: 0.0817498192191124\n",
      "epoch 4 batch 400 [40000/60000] training loss: 0.07403375953435898\n",
      "epoch 4 batch 500 [50000/60000] training loss: 0.03517331928014755\n",
      "Test Accuracy: 9723/10000 (tx 97.23%, err 2.77%)\n",
      "\n",
      "tensor([[      963.,         0.,         5.,         0.,         0.,         4.,\n",
      "                 5.,         0.,         3.,         3.],\n",
      "        [        0.,      1123.,         2.,         0.,         0.,         1.,\n",
      "                 3.,         6.,         0.,         4.],\n",
      "        [        1.,         2.,      1006.,         5.,         4.,         0.,\n",
      "                 2.,        12.,         2.,         0.],\n",
      "        [        2.,         1.,         4.,       991.,         0.,        10.,\n",
      "                 1.,         5.,         9.,         7.],\n",
      "        [        2.,         0.,         4.,         0.,       967.,         5.,\n",
      "                 8.,         1.,         3.,        19.],\n",
      "        [        1.,         1.,         0.,         3.,         0.,       852.,\n",
      "                 3.,         0.,         3.,         4.],\n",
      "        [        5.,         5.,         2.,         0.,         2.,         9.,\n",
      "               933.,         0.,         7.,         1.],\n",
      "        [        3.,         0.,         6.,         5.,         1.,         1.,\n",
      "                 0.,       985.,         5.,         6.],\n",
      "        [        1.,         3.,         3.,         4.,         1.,         8.,\n",
      "                 3.,         3.,       939.,         1.],\n",
      "        [        2.,         0.,         0.,         2.,         7.,         2.,\n",
      "                 0.,        16.,         3.,       964.]])\n",
      "epoch 5 batch 0 [0/60000] training loss: 0.02940119244158268\n",
      "epoch 5 batch 100 [10000/60000] training loss: 0.18375670909881592\n",
      "epoch 5 batch 200 [20000/60000] training loss: 0.021391406655311584\n",
      "epoch 5 batch 300 [30000/60000] training loss: 0.10026857256889343\n",
      "epoch 5 batch 400 [40000/60000] training loss: 0.09487758576869965\n",
      "epoch 5 batch 500 [50000/60000] training loss: 0.0590779073536396\n",
      "Test Accuracy: 9758/10000 (tx 97.58%, err 2.42%)\n",
      "\n",
      "tensor([[      968.,         0.,         5.,         1.,         1.,         3.,\n",
      "                 6.,         1.,         4.,         3.],\n",
      "        [        0.,      1129.,         2.,         0.,         0.,         1.,\n",
      "                 3.,         8.,         1.,         4.],\n",
      "        [        1.,         1.,      1006.,         5.,         5.,         0.,\n",
      "                 2.,         4.,         1.,         0.],\n",
      "        [        1.,         1.,         3.,       987.,         0.,        10.,\n",
      "                 1.,         1.,         6.,         6.],\n",
      "        [        2.,         0.,         4.,         0.,       952.,         1.,\n",
      "                 7.,         0.,         4.,         6.],\n",
      "        [        0.,         1.,         0.,         3.,         0.,       866.,\n",
      "                 6.,         0.,         6.,         2.],\n",
      "        [        2.,         1.,         0.,         0.,         2.,         3.,\n",
      "               926.,         0.,         4.,         1.],\n",
      "        [        2.,         1.,         9.,         8.,         4.,         1.,\n",
      "                 1.,      1007.,         5.,         7.],\n",
      "        [        2.,         1.,         3.,         3.,         0.,         5.,\n",
      "                 6.,         2.,       937.,         0.],\n",
      "        [        2.,         0.,         0.,         3.,        18.,         2.,\n",
      "                 0.,         5.,         6.,       980.]])\n",
      "epoch 6 batch 0 [0/60000] training loss: 0.026806671172380447\n",
      "epoch 6 batch 100 [10000/60000] training loss: 0.0554518923163414\n",
      "epoch 6 batch 200 [20000/60000] training loss: 0.03799345716834068\n",
      "epoch 6 batch 300 [30000/60000] training loss: 0.035005517303943634\n",
      "epoch 6 batch 400 [40000/60000] training loss: 0.016202790662646294\n",
      "epoch 6 batch 500 [50000/60000] training loss: 0.12648096680641174\n",
      "Test Accuracy: 9767/10000 (tx 97.67%, err 2.33%)\n",
      "\n",
      "tensor([[      972.,         0.,         5.,         1.,         3.,         4.,\n",
      "                 5.,         1.,         3.,         3.],\n",
      "        [        0.,      1128.,         2.,         0.,         0.,         1.,\n",
      "                 3.,         6.,         0.,         5.],\n",
      "        [        1.,         0.,      1004.,         0.,         5.,         0.,\n",
      "                 2.,         5.,         2.,         0.],\n",
      "        [        1.,         1.,         5.,       998.,         0.,        16.,\n",
      "                 1.,         1.,        10.,         6.],\n",
      "        [        0.,         0.,         4.,         0.,       955.,         2.,\n",
      "                 3.,         0.,         3.,         9.],\n",
      "        [        1.,         1.,         0.,         1.,         0.,       851.,\n",
      "                 4.,         0.,         3.,         3.],\n",
      "        [        1.,         2.,         3.,         0.,         3.,         6.,\n",
      "               935.,         0.,         3.,         1.],\n",
      "        [        2.,         1.,         6.,         4.,         2.,         1.,\n",
      "                 1.,      1010.,         5.,         9.],\n",
      "        [        2.,         2.,         3.,         4.,         0.,         7.,\n",
      "                 4.,         1.,       943.,         2.],\n",
      "        [        0.,         0.,         0.,         2.,        14.,         4.,\n",
      "                 0.,         4.,         2.,       971.]])\n",
      "epoch 7 batch 0 [0/60000] training loss: 0.05110161378979683\n",
      "epoch 7 batch 100 [10000/60000] training loss: 0.015758903697133064\n",
      "epoch 7 batch 200 [20000/60000] training loss: 0.04615355655550957\n",
      "epoch 7 batch 300 [30000/60000] training loss: 0.07023891806602478\n",
      "epoch 7 batch 400 [40000/60000] training loss: 0.06244282424449921\n",
      "epoch 7 batch 500 [50000/60000] training loss: 0.009731973521411419\n",
      "Test Accuracy: 9785/10000 (tx 97.85%, err 2.15%)\n",
      "\n",
      "tensor([[      963.,         0.,         4.,         0.,         1.,         2.,\n",
      "                 2.,         0.,         2.,         3.],\n",
      "        [        0.,      1123.,         2.,         0.,         0.,         1.,\n",
      "                 3.,         5.,         0.,         2.],\n",
      "        [        1.,         2.,      1008.,         4.,         3.,         0.,\n",
      "                 2.,         4.,         2.,         0.],\n",
      "        [        1.,         2.,         2.,       987.,         0.,         4.,\n",
      "                 1.,         0.,         3.,         5.],\n",
      "        [        2.,         0.,         3.,         0.,       966.,         1.,\n",
      "                 7.,         0.,         3.,        13.],\n",
      "        [        3.,         1.,         0.,         3.,         0.,       873.,\n",
      "                 3.,         0.,         5.,         2.],\n",
      "        [        4.,         2.,         2.,         0.,         4.,         2.,\n",
      "               937.,         0.,         5.,         3.],\n",
      "        [        2.,         1.,         8.,         9.,         2.,         1.,\n",
      "                 1.,      1013.,         5.,         7.],\n",
      "        [        2.,         4.,         3.,         4.,         1.,         6.,\n",
      "                 2.,         2.,       946.,         5.],\n",
      "        [        2.,         0.,         0.,         3.,         5.,         2.,\n",
      "                 0.,         4.,         3.,       969.]])\n",
      "epoch 8 batch 0 [0/60000] training loss: 0.04448855295777321\n",
      "epoch 8 batch 100 [10000/60000] training loss: 0.013027033768594265\n",
      "epoch 8 batch 200 [20000/60000] training loss: 0.05085478723049164\n",
      "epoch 8 batch 300 [30000/60000] training loss: 0.03899812325835228\n",
      "epoch 8 batch 400 [40000/60000] training loss: 0.0446607880294323\n",
      "epoch 8 batch 500 [50000/60000] training loss: 0.057570680975914\n",
      "Test Accuracy: 9784/10000 (tx 97.84%, err 2.16%)\n",
      "\n",
      "tensor([[      968.,         0.,         4.,         1.,         1.,         3.,\n",
      "                 4.,         1.,         5.,         3.],\n",
      "        [        0.,      1124.,         3.,         0.,         0.,         0.,\n",
      "                 3.,         5.,         0.,         3.],\n",
      "        [        1.,         3.,      1010.,         3.,         5.,         0.,\n",
      "                 2.,         7.,         3.,         0.],\n",
      "        [        1.,         2.,         3.,       995.,         1.,         8.,\n",
      "                 1.,         4.,         2.,         4.],\n",
      "        [        1.,         0.,         4.,         0.,       957.,         1.,\n",
      "                 8.,         0.,         3.,        10.],\n",
      "        [        2.,         1.,         0.,         3.,         0.,       869.,\n",
      "                 4.,         0.,         4.,         2.],\n",
      "        [        2.,         2.,         0.,         0.,         1.,         2.,\n",
      "               933.,         0.,         3.,         1.],\n",
      "        [        1.,         1.,         5.,         2.,         2.,         1.,\n",
      "                 0.,      1001.,         4.,         4.],\n",
      "        [        2.,         2.,         3.,         4.,         0.,         6.,\n",
      "                 3.,         3.,       945.,         0.],\n",
      "        [        2.,         0.,         0.,         2.,        15.,         2.,\n",
      "                 0.,         7.,         5.,       982.]])\n",
      "epoch 9 batch 0 [0/60000] training loss: 0.051567837595939636\n",
      "epoch 9 batch 100 [10000/60000] training loss: 0.02572793886065483\n",
      "epoch 9 batch 200 [20000/60000] training loss: 0.03725221008062363\n",
      "epoch 9 batch 300 [30000/60000] training loss: 0.0668899193406105\n",
      "epoch 9 batch 400 [40000/60000] training loss: 0.03434986248612404\n",
      "epoch 9 batch 500 [50000/60000] training loss: 0.0107277175411582\n",
      "Test Accuracy: 9792/10000 (tx 97.92%, err 2.08%)\n",
      "\n",
      "tensor([[      967.,         0.,         4.,         1.,         2.,         4.,\n",
      "                 4.,         1.,         4.,         3.],\n",
      "        [        0.,      1123.,         1.,         0.,         0.,         1.,\n",
      "                 2.,         4.,         0.,         2.],\n",
      "        [        1.,         4.,      1016.,         7.,         7.,         0.,\n",
      "                 2.,        10.,         3.,         0.],\n",
      "        [        1.,         1.,         0.,       990.,         0.,         8.,\n",
      "                 1.,         1.,         2.,         4.],\n",
      "        [        1.,         0.,         1.,         0.,       954.,         1.,\n",
      "                 5.,         0.,         1.,         2.],\n",
      "        [        1.,         1.,         0.,         2.,         0.,       865.,\n",
      "                 2.,         0.,         2.,         2.],\n",
      "        [        2.,         2.,         2.,         0.,         2.,         4.,\n",
      "               940.,         0.,         5.,         3.],\n",
      "        [        2.,         1.,         5.,         4.,         2.,         1.,\n",
      "                 0.,      1004.,         3.,         4.],\n",
      "        [        3.,         3.,         3.,         4.,         1.,         7.,\n",
      "                 2.,         4.,       952.,         8.],\n",
      "        [        2.,         0.,         0.,         2.,        14.,         1.,\n",
      "                 0.,         4.,         2.,       981.]])\n"
     ]
    }
   ],
   "source": [
    "# Entrainement et évaluation\n",
    "\n",
    "for epoch in range(10):\n",
    "    # training\n",
    "    model.train() \n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx %100 ==0:\n",
    "            print('epoch {} batch {} [{}/{}] training loss: {}'.format(epoch,batch_idx,batch_idx*len(x),\n",
    "                    len(train_loader.dataset),loss.item()))\n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        confusion = torch.zeros(NUM_CLASSES,NUM_CLASSES)\n",
    "        for batch_idx, (x, target) in enumerate(test_loader):\n",
    "            x, target = x.to(device), target.to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, target)\n",
    "            # _, prediction = torch.max(out.data, 1)\n",
    "            prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "            # since 'prediction' and 'target' may be on the GPU memory\n",
    "            # thus (i,j) are on the GPU as well. They must be transfered\n",
    "            # to the CPU, where 'confusion' has been allocated\n",
    "            for i,j in zip(prediction,target):\n",
    "                confusion[i.to(\"cpu\"),j.to(\"cpu\")] += 1\n",
    "    taux_classif = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test Accuracy: {}/{} (tx {:.2f}%, err {:.2f}%)\\n'.format(correct,\n",
    "     len(test_loader.dataset), taux_classif, 100.-taux_classif))\n",
    "    torch.set_printoptions(sci_mode=False)\n",
    "    print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modélisation CNN\n",
    "\n",
    "Consulter la [documentation PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d) de la class `Conv2D`.\n",
    "\n",
    "> class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "Taille d'entrée : (N,Cin,H,W) x (N,Cin​,H,W) \n",
    "\n",
    "Taille de sortie : (N,Cout,Hout,Wout) x (N,Cout​,Hout​,Wout​)\n",
    "\n",
    "avec : \n",
    "* N : batch size\n",
    "* Cin et Cout : nombre de filtres respectivement en entrée et sortie (channels)\n",
    "* H et W : height and width des filtres en entrée\n",
    "* Hout et Wout : height and width des filtres en sortie\n",
    "\n",
    "TODO : calcul des dimensions de sortie des couches de convolution et de pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implémentation d'un CNN avec deux couches convolutives\n",
    "# v1 sans Dropout\n",
    "# v2 ajouter une couche de Dropout après les 2 couches de conv\n",
    "\n",
    "NUM_CONV_1=10 # try 32\n",
    "NUM_CONV_2=20 # try 64\n",
    "NUM_FC=500 # try 1024\n",
    "\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet,self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(1,NUM_CONV_1,5,1) # kernel_size = 5\n",
    "        self.conv_2 = nn.Conv2d(NUM_CONV_1,NUM_CONV_2,5,1) # kernel_size = 5\n",
    "        # self.drop = nn.Dropout2d()\n",
    "        self.fc_1 = nn.Linear(4*4*NUM_CONV_2, NUM_FC)\n",
    "        self.fc_2 = nn.Linear(NUM_FC,NUM_CLASSES)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        # x = F.relu(self.drop(self.conv_2(x)))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = x.view(-1,4*4*NUM_CONV_2)\n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        return x\n",
    "        # en utilisant loss = F.nll_loss(output, target) on peut faire\n",
    "        # return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : de manière équivalente, en utilisant `loss = F.nll_loss(output, target)` au lieu de `loss = CrossEntropyLoss()` on peut écrire :\n",
    "\n",
    "> return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNNet()\n",
    "model.to(device) # pour faire passer le modèle sur GPU / CPU\n",
    "\n",
    "# optimization hyperparameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05) # try lr=0.01, momentum=0.9\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 [0/60000] training loss: 2.316574811935425\n",
      "epoch 0 batch 100 [10000/60000] training loss: 0.43379589915275574\n",
      "epoch 0 batch 200 [20000/60000] training loss: 0.18040795624256134\n",
      "epoch 0 batch 300 [30000/60000] training loss: 0.1653175950050354\n",
      "epoch 0 batch 400 [40000/60000] training loss: 0.07835887372493744\n",
      "epoch 0 batch 500 [50000/60000] training loss: 0.1743411123752594\n",
      "Test Accuracy: 9725/10000 (tx 97.25%, err 2.75%)\n",
      "\n",
      "tensor([[      974.,         0.,         6.,         1.,         0.,         4.,\n",
      "                 8.,         1.,         7.,        10.],\n",
      "        [        0.,      1123.,         2.,         0.,         0.,         0.,\n",
      "                 2.,         6.,         0.,         7.],\n",
      "        [        1.,         2.,       990.,         5.,         0.,         1.,\n",
      "                 0.,         8.,         5.,         0.],\n",
      "        [        0.,         1.,         1.,       976.,         0.,         6.,\n",
      "                 0.,         0.,         2.,         6.],\n",
      "        [        0.,         0.,         7.,         0.,       975.,         1.,\n",
      "                 5.,         0.,         6.,        29.],\n",
      "        [        0.,         0.,         0.,        12.,         0.,       871.,\n",
      "                 1.,         0.,         2.,         9.],\n",
      "        [        2.,         6.,         1.,         0.,         3.,         6.,\n",
      "               941.,         0.,         5.,         0.],\n",
      "        [        1.,         1.,        18.,        10.,         1.,         1.,\n",
      "                 0.,      1012.,         9.,        14.],\n",
      "        [        2.,         2.,         7.,         5.,         2.,         2.,\n",
      "                 1.,         1.,       936.,         7.],\n",
      "        [        0.,         0.,         0.,         1.,         1.,         0.,\n",
      "                 0.,         0.,         2.,       927.]])\n",
      "epoch 1 batch 0 [0/60000] training loss: 0.05653552711009979\n",
      "epoch 1 batch 100 [10000/60000] training loss: 0.10519974678754807\n",
      "epoch 1 batch 200 [20000/60000] training loss: 0.09980317205190659\n",
      "epoch 1 batch 300 [30000/60000] training loss: 0.039737503975629807\n",
      "epoch 1 batch 400 [40000/60000] training loss: 0.0359056331217289\n",
      "epoch 1 batch 500 [50000/60000] training loss: 0.09710274636745453\n",
      "Test Accuracy: 9822/10000 (tx 98.22%, err 1.78%)\n",
      "\n",
      "tensor([[      975.,         0.,         2.,         1.,         1.,         2.,\n",
      "                 9.,         0.,         4.,         5.],\n",
      "        [        0.,      1125.,         1.,         0.,         0.,         0.,\n",
      "                 2.,         1.,         1.,         4.],\n",
      "        [        0.,         3.,      1018.,         1.,         2.,         0.,\n",
      "                 1.,        13.,         1.,         1.],\n",
      "        [        0.,         1.,         3.,       992.,         0.,         6.,\n",
      "                 1.,         3.,         3.,         6.],\n",
      "        [        0.,         0.,         0.,         0.,       968.,         0.,\n",
      "                 1.,         0.,         1.,         5.],\n",
      "        [        0.,         1.,         0.,         5.,         0.,       878.,\n",
      "                 4.,         0.,         1.,         7.],\n",
      "        [        0.,         1.,         0.,         0.,         3.,         2.,\n",
      "               937.,         0.,         1.,         0.],\n",
      "        [        2.,         1.,         5.,         6.,         2.,         1.,\n",
      "                 0.,      1010.,         2.,        12.],\n",
      "        [        3.,         3.,         3.,         5.,         2.,         3.,\n",
      "                 3.,         1.,       959.,         9.],\n",
      "        [        0.,         0.,         0.,         0.,         4.,         0.,\n",
      "                 0.,         0.,         1.,       960.]])\n",
      "epoch 2 batch 0 [0/60000] training loss: 0.030199678614735603\n",
      "epoch 2 batch 100 [10000/60000] training loss: 0.07128003984689713\n",
      "epoch 2 batch 200 [20000/60000] training loss: 0.07636607438325882\n",
      "epoch 2 batch 300 [30000/60000] training loss: 0.04322155565023422\n",
      "epoch 2 batch 400 [40000/60000] training loss: 0.015764839947223663\n",
      "epoch 2 batch 500 [50000/60000] training loss: 0.061603255569934845\n",
      "Test Accuracy: 9866/10000 (tx 98.66%, err 1.34%)\n",
      "\n",
      "tensor([[      974.,         0.,         0.,         1.,         0.,         2.,\n",
      "                 3.,         0.,         2.,         3.],\n",
      "        [        0.,      1128.,         1.,         0.,         0.,         0.,\n",
      "                 2.,         1.,         1.,         3.],\n",
      "        [        0.,         1.,      1021.,         1.,         2.,         0.,\n",
      "                 1.,         4.,         3.,         0.],\n",
      "        [        1.,         1.,         4.,       997.,         0.,         5.,\n",
      "                 1.,         2.,         4.,         4.],\n",
      "        [        0.,         0.,         2.,         0.,       971.,         0.,\n",
      "                 2.,         0.,         1.,         7.],\n",
      "        [        0.,         1.,         0.,         5.,         0.,       880.,\n",
      "                 7.,         0.,         2.,         3.],\n",
      "        [        1.,         1.,         0.,         0.,         1.,         1.,\n",
      "               941.,         0.,         1.,         0.],\n",
      "        [        1.,         2.,         3.,         4.,         2.,         1.,\n",
      "                 0.,      1018.,         3.,         7.],\n",
      "        [        3.,         1.,         1.,         2.,         2.,         2.,\n",
      "                 1.,         1.,       955.,         1.],\n",
      "        [        0.,         0.,         0.,         0.,         4.,         1.,\n",
      "                 0.,         2.,         2.,       981.]])\n",
      "epoch 3 batch 0 [0/60000] training loss: 0.015249793417751789\n",
      "epoch 3 batch 100 [10000/60000] training loss: 0.04467739164829254\n",
      "epoch 3 batch 200 [20000/60000] training loss: 0.056480903178453445\n",
      "epoch 3 batch 300 [30000/60000] training loss: 0.04147293046116829\n",
      "epoch 3 batch 400 [40000/60000] training loss: 0.021013963967561722\n",
      "epoch 3 batch 500 [50000/60000] training loss: 0.008871044032275677\n",
      "Test Accuracy: 9878/10000 (tx 98.78%, err 1.22%)\n",
      "\n",
      "tensor([[      977.,         0.,         0.,         2.,         0.,         2.,\n",
      "                 6.,         0.,         5.,         5.],\n",
      "        [        0.,      1130.,         2.,         0.,         0.,         0.,\n",
      "                 2.,         1.,         1.,         3.],\n",
      "        [        0.,         1.,      1024.,         2.,         2.,         0.,\n",
      "                 0.,         6.,         3.,         1.],\n",
      "        [        0.,         0.,         0.,      1000.,         0.,         4.,\n",
      "                 1.,         1.,         2.,         3.],\n",
      "        [        0.,         0.,         2.,         0.,       974.,         0.,\n",
      "                 2.,         0.,         1.,         8.],\n",
      "        [        0.,         1.,         0.,         3.,         0.,       882.,\n",
      "                 5.,         0.,         1.,         2.],\n",
      "        [        0.,         1.,         0.,         0.,         1.,         1.,\n",
      "               942.,         0.,         1.,         0.],\n",
      "        [        1.,         2.,         3.,         2.,         2.,         1.,\n",
      "                 0.,      1019.,         2.,         8.],\n",
      "        [        2.,         0.,         1.,         1.,         0.,         2.,\n",
      "                 0.,         1.,       955.,         4.],\n",
      "        [        0.,         0.,         0.,         0.,         3.,         0.,\n",
      "                 0.,         0.,         3.,       975.]])\n",
      "epoch 4 batch 0 [0/60000] training loss: 0.03872012719511986\n",
      "epoch 4 batch 100 [10000/60000] training loss: 0.05376860126852989\n",
      "epoch 4 batch 200 [20000/60000] training loss: 0.011329561471939087\n",
      "epoch 4 batch 300 [30000/60000] training loss: 0.043843790888786316\n",
      "epoch 4 batch 400 [40000/60000] training loss: 0.009306472726166248\n",
      "epoch 4 batch 500 [50000/60000] training loss: 0.17144307494163513\n",
      "Test Accuracy: 9874/10000 (tx 98.74%, err 1.26%)\n",
      "\n",
      "tensor([[      976.,         0.,         0.,         1.,         1.,         2.,\n",
      "                 4.,         0.,         3.,         2.],\n",
      "        [        0.,      1128.,         2.,         0.,         0.,         0.,\n",
      "                 3.,         1.,         1.,         2.],\n",
      "        [        1.,         1.,      1025.,         1.,         2.,         0.,\n",
      "                 1.,        10.,         4.,         1.],\n",
      "        [        0.,         1.,         0.,      1000.,         0.,         4.,\n",
      "                 1.,         2.,         3.,         0.],\n",
      "        [        0.,         0.,         2.,         0.,       973.,         0.,\n",
      "                 0.,         0.,         1.,         5.],\n",
      "        [        0.,         2.,         0.,         5.,         0.,       883.,\n",
      "                13.,         0.,         2.,         4.],\n",
      "        [        0.,         1.,         0.,         0.,         1.,         1.,\n",
      "               936.,         0.,         1.,         0.],\n",
      "        [        1.,         2.,         2.,         0.,         0.,         1.,\n",
      "                 0.,      1006.,         2.,         0.],\n",
      "        [        2.,         0.,         1.,         0.,         0.,         1.,\n",
      "                 0.,         1.,       952.,         0.],\n",
      "        [        0.,         0.,         0.,         3.,         5.,         0.,\n",
      "                 0.,         8.,         5.,       995.]])\n",
      "epoch 5 batch 0 [0/60000] training loss: 0.008815840817987919\n",
      "epoch 5 batch 100 [10000/60000] training loss: 0.0024448910262435675\n",
      "epoch 5 batch 200 [20000/60000] training loss: 0.04456479847431183\n",
      "epoch 5 batch 300 [30000/60000] training loss: 0.019859962165355682\n",
      "epoch 5 batch 400 [40000/60000] training loss: 0.02807438187301159\n",
      "epoch 5 batch 500 [50000/60000] training loss: 0.0011781882494688034\n",
      "Test Accuracy: 9876/10000 (tx 98.76%, err 1.24%)\n",
      "\n",
      "tensor([[      974.,         0.,         0.,         0.,         1.,         2.,\n",
      "                 4.,         0.,         1.,         2.],\n",
      "        [        0.,      1128.,         0.,         0.,         0.,         1.,\n",
      "                 2.,         1.,         0.,         2.],\n",
      "        [        1.,         2.,      1025.,         1.,         2.,         0.,\n",
      "                 1.,         7.,         3.,         1.],\n",
      "        [        0.,         1.,         2.,      1007.,         1.,        12.,\n",
      "                 1.,         3.,         4.,         5.],\n",
      "        [        0.,         0.,         2.,         0.,       970.,         0.,\n",
      "                 5.,         0.,         1.,         5.],\n",
      "        [        0.,         1.,         0.,         0.,         0.,       870.,\n",
      "                 2.,         0.,         0.,         1.],\n",
      "        [        0.,         1.,         0.,         0.,         1.,         2.,\n",
      "               941.,         0.,         1.,         0.],\n",
      "        [        1.,         1.,         2.,         0.,         3.,         1.,\n",
      "                 0.,      1015.,         2.,         4.],\n",
      "        [        2.,         1.,         1.,         1.,         2.,         2.,\n",
      "                 2.,         1.,       960.,         3.],\n",
      "        [        2.,         0.,         0.,         1.,         2.,         2.,\n",
      "                 0.,         1.,         2.,       986.]])\n",
      "epoch 6 batch 0 [0/60000] training loss: 0.005354875698685646\n",
      "epoch 6 batch 100 [10000/60000] training loss: 0.0024687505792826414\n",
      "epoch 6 batch 200 [20000/60000] training loss: 0.02852892316877842\n",
      "epoch 6 batch 300 [30000/60000] training loss: 0.003147541079670191\n",
      "epoch 6 batch 400 [40000/60000] training loss: 0.02279476635158062\n",
      "epoch 6 batch 500 [50000/60000] training loss: 0.030998092144727707\n",
      "Test Accuracy: 9897/10000 (tx 98.97%, err 1.03%)\n",
      "\n",
      "tensor([[      976.,         0.,         0.,         1.,         0.,         2.,\n",
      "                 3.,         0.,         1.,         1.],\n",
      "        [        0.,      1133.,         2.,         0.,         0.,         0.,\n",
      "                 2.,        10.,         1.,         2.],\n",
      "        [        0.,         0.,      1021.,         0.,         0.,         0.,\n",
      "                 0.,         3.,         1.,         0.],\n",
      "        [        0.,         0.,         3.,      1008.,         0.,        10.,\n",
      "                 1.,         4.,         3.,         1.],\n",
      "        [        0.,         0.,         2.,         0.,       976.,         0.,\n",
      "                 1.,         0.,         1.,         4.],\n",
      "        [        0.,         1.,         0.,         0.,         0.,       875.,\n",
      "                 4.,         0.,         0.,         2.],\n",
      "        [        1.,         0.,         0.,         0.,         1.,         1.,\n",
      "               947.,         0.,         1.,         1.],\n",
      "        [        1.,         1.,         2.,         0.,         0.,         1.,\n",
      "                 0.,      1006.,         2.,         2.],\n",
      "        [        2.,         0.,         2.,         1.,         0.,         3.,\n",
      "                 0.,         2.,       960.,         1.],\n",
      "        [        0.,         0.,         0.,         0.,         5.,         0.,\n",
      "                 0.,         3.,         4.,       995.]])\n",
      "epoch 7 batch 0 [0/60000] training loss: 0.01894845813512802\n",
      "epoch 7 batch 100 [10000/60000] training loss: 0.03332081809639931\n",
      "epoch 7 batch 200 [20000/60000] training loss: 0.04497299715876579\n",
      "epoch 7 batch 300 [30000/60000] training loss: 0.06398443877696991\n",
      "epoch 7 batch 400 [40000/60000] training loss: 0.03720005601644516\n",
      "epoch 7 batch 500 [50000/60000] training loss: 0.005255646072328091\n",
      "Test Accuracy: 9893/10000 (tx 98.93%, err 1.07%)\n",
      "\n",
      "tensor([[      974.,         0.,         0.,         1.,         0.,         2.,\n",
      "                 3.,         0.,         2.,         2.],\n",
      "        [        0.,      1132.,         1.,         0.,         0.,         1.,\n",
      "                 2.,         5.,         1.,         2.],\n",
      "        [        0.,         0.,      1027.,         1.,         1.,         0.,\n",
      "                 0.,         1.,         2.,         0.],\n",
      "        [        0.,         0.,         0.,       996.,         0.,         6.,\n",
      "                 1.,         2.,         1.,         0.],\n",
      "        [        0.,         0.,         1.,         0.,       969.,         0.,\n",
      "                 1.,         0.,         1.,         3.],\n",
      "        [        0.,         1.,         0.,         4.,         0.,       879.,\n",
      "                 3.,         0.,         1.,         3.],\n",
      "        [        3.,         1.,         0.,         0.,         2.,         1.,\n",
      "               948.,         0.,         1.,         0.],\n",
      "        [        1.,         1.,         2.,         2.,         2.,         1.,\n",
      "                 0.,      1018.,         2.,         6.],\n",
      "        [        2.,         0.,         1.,         3.,         2.,         2.,\n",
      "                 0.,         1.,       960.,         3.],\n",
      "        [        0.,         0.,         0.,         3.,         6.,         0.,\n",
      "                 0.,         1.,         3.,       990.]])\n",
      "epoch 8 batch 0 [0/60000] training loss: 0.006807037629187107\n",
      "epoch 8 batch 100 [10000/60000] training loss: 0.011552521958947182\n",
      "epoch 8 batch 200 [20000/60000] training loss: 0.0005712092388421297\n",
      "epoch 8 batch 300 [30000/60000] training loss: 0.018746880814433098\n",
      "epoch 8 batch 400 [40000/60000] training loss: 0.008594897575676441\n",
      "epoch 8 batch 500 [50000/60000] training loss: 0.037455275654792786\n",
      "Test Accuracy: 9901/10000 (tx 99.01%, err 0.99%)\n",
      "\n",
      "tensor([[      976.,         0.,         3.,         2.,         0.,         2.,\n",
      "                 3.,         0.,         2.,         2.],\n",
      "        [        0.,      1131.,         0.,         0.,         0.,         0.,\n",
      "                 2.,         2.,         1.,         2.],\n",
      "        [        0.,         0.,      1022.,         1.,         0.,         0.,\n",
      "                 0.,         4.,         2.,         1.],\n",
      "        [        0.,         0.,         1.,      1000.,         0.,         6.,\n",
      "                 0.,         1.,         1.,         0.],\n",
      "        [        0.,         0.,         2.,         0.,       979.,         0.,\n",
      "                 1.,         0.,         1.,         7.],\n",
      "        [        0.,         2.,         0.,         3.,         0.,       880.,\n",
      "                 5.,         0.,         2.,         2.],\n",
      "        [        2.,         1.,         0.,         0.,         1.,         1.,\n",
      "               947.,         0.,         0.,         0.],\n",
      "        [        1.,         1.,         3.,         3.,         0.,         1.,\n",
      "                 0.,      1020.,         2.,         6.],\n",
      "        [        1.,         0.,         1.,         0.,         0.,         2.,\n",
      "                 0.,         1.,       960.,         3.],\n",
      "        [        0.,         0.,         0.,         1.,         2.,         0.,\n",
      "                 0.,         0.,         3.,       986.]])\n",
      "epoch 9 batch 0 [0/60000] training loss: 0.0016362358583137393\n",
      "epoch 9 batch 100 [10000/60000] training loss: 0.0378396101295948\n",
      "epoch 9 batch 200 [20000/60000] training loss: 0.0102242948487401\n",
      "epoch 9 batch 300 [30000/60000] training loss: 0.0052854870446026325\n",
      "epoch 9 batch 400 [40000/60000] training loss: 0.03468858823180199\n",
      "epoch 9 batch 500 [50000/60000] training loss: 0.02509629726409912\n",
      "Test Accuracy: 9901/10000 (tx 99.01%, err 0.99%)\n",
      "\n",
      "tensor([[      978.,         0.,         0.,         1.,         0.,         3.,\n",
      "                 5.,         0.,         3.,         1.],\n",
      "        [        0.,      1132.,         1.,         0.,         0.,         0.,\n",
      "                 2.,         2.,         1.,         2.],\n",
      "        [        0.,         0.,      1026.,         1.,         0.,         0.,\n",
      "                 0.,         5.,         3.,         0.],\n",
      "        [        0.,         0.,         0.,      1006.,         0.,         9.,\n",
      "                 1.,         1.,         1.,         1.],\n",
      "        [        0.,         0.,         2.,         0.,       974.,         0.,\n",
      "                 3.,         0.,         1.,         4.],\n",
      "        [        0.,         1.,         0.,         2.,         0.,       876.,\n",
      "                 3.,         0.,         2.,         3.],\n",
      "        [        1.,         1.,         0.,         0.,         1.,         1.,\n",
      "               944.,         0.,         0.,         0.],\n",
      "        [        1.,         1.,         2.,         0.,         0.,         1.,\n",
      "                 0.,      1018.,         2.,         5.],\n",
      "        [        0.,         0.,         1.,         0.,         2.,         2.,\n",
      "                 0.,         1.,       958.,         4.],\n",
      "        [        0.,         0.,         0.,         0.,         5.,         0.,\n",
      "                 0.,         1.,         3.,       989.]])\n"
     ]
    }
   ],
   "source": [
    "# Entrainement et évaluation\n",
    "\n",
    "for epoch in range(10):\n",
    "    # training\n",
    "    model.train() \n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx %100 ==0:\n",
    "            print('epoch {} batch {} [{}/{}] training loss: {}'.format(epoch,batch_idx,batch_idx*len(x),\n",
    "                    len(train_loader.dataset),loss.item()))\n",
    "    # testing\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        confusion = torch.zeros(NUM_CLASSES,NUM_CLASSES)\n",
    "        for batch_idx, (x, target) in enumerate(test_loader):\n",
    "            x, target = x.to(device), target.to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, target)\n",
    "            # _, prediction = torch.max(out.data, 1)\n",
    "            prediction = out.argmax(dim=1, keepdim=True) # index of the max log-probability\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "            # since 'prediction' and 'target' may be on the GPU memory\n",
    "            # thus (i,j) are on the GPU as well. They must be transfered\n",
    "            # to the CPU, where 'confusion' has been allocated\n",
    "            for i,j in zip(prediction,target):\n",
    "                confusion[i.to(\"cpu\"),j.to(\"cpu\")] += 1\n",
    "    taux_classif = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test Accuracy: {}/{} (tx {:.2f}%, err {:.2f}%)\\n'.format(correct,\n",
    "     len(test_loader.dataset), taux_classif, 100.-taux_classif))\n",
    "    torch.set_printoptions(sci_mode=False)\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calcul de la taille d'un modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.652 MB\n"
     ]
    }
   ],
   "source": [
    "# parametres + buffers (e.g. batch norm)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    \"\"\" \n",
    "    in megabites --> divide by 1024**2\n",
    "    \"\"\"\n",
    "    param_size = 0\n",
    "    for p in model.parameters() :\n",
    "        param_size += p.numel()*p.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for b in model.buffers() :\n",
    "        buffer_size += b.numel()*b.element_size()\n",
    "\n",
    "    return (param_size + buffer_size) / 1024**2\n",
    "\n",
    "print(round(get_model_size(model),3), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sauvegarde des poids du modèle__\n",
    "\n",
    "Il y a deux manières de sauvegarder un modèle suivant si on utilise `state_dict()` ou pas. Comparer avec la [documentation PyTorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
    "\n",
    "> A state_dict is simply a Python dictionary object that maps each layer to its parameter tensor. Note that only layers with learnable parameters (convolutional layers, linear layers, etc.) and registered buffers (batchnorm’s running_mean) have entries in the model’s state_dict. Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizer’s state, as well as the hyperparameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNNet(\n",
      "  (conv_1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv_2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc_1): Linear(in_features=320, out_features=500, bias=True)\n",
      "  (fc_2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n",
      "CNNNet(\n",
      "  (conv_1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv_2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc_1): Linear(in_features=320, out_features=500, bias=True)\n",
      "  (fc_2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_2632\\3024922651.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1 = torch.load('./my_cnn.pth')\n"
     ]
    }
   ],
   "source": [
    "# sauvegarde\n",
    "print(model)\n",
    "torch.save(model, 'my_cnn.pth')\n",
    "\n",
    "# chargement\n",
    "model1 = torch.load('./my_cnn.pth')\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv_1.weight', 'conv_1.bias', 'conv_2.weight', 'conv_2.bias', 'fc_1.weight', 'fc_1.bias', 'fc_2.weight', 'fc_2.bias'])\n",
      "CNNNet(\n",
      "  (conv_1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv_2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc_1): Linear(in_features=320, out_features=500, bias=True)\n",
      "  (fc_2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_2632\\673637721.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2.load_state_dict(torch.load('my_cnn_params.pth'))\n"
     ]
    }
   ],
   "source": [
    "# Utilisation de state_dict : on accède aux paramètres du modèle\n",
    "\n",
    "# sauvegarde\n",
    "print(model.state_dict().keys())\n",
    "torch.save(model.state_dict(), 'my_cnn_params.pth')\n",
    "\n",
    "# chargement : il faut définir le modèle puis charger les poids\n",
    "model2 = CNNNet()\n",
    "model2.load_state_dict(torch.load('my_cnn_params.pth'))\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualisation des feature maps (cartes d'activation)__\n",
    "\n",
    "Se référer au script `visualize_cnn_features.py`. Il utilise les poids du CNN, que l'on vient de sauvegarder. \n",
    "\n",
    "Autres références pour visualiser les cartes d'activation d'un CNN : [un réseau plus profond](https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/)  et [une autre méthode de visualisation](https://blbadger.github.io/feature-visualization.html) (en optimisant l'entrée de manière à maximiser la réponse d'un filtre donné)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles LSTM et Bi-LSTM\n",
    "\n",
    "Se référer à la [documentation PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) pour le module `LSTM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LSTM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "sequence_length = 28 # on voit une image comme une chaine de 28 mots\n",
    "input_size = 28 # chaque mot fait 28 caractères\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LSTM model\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self,in_size,hidden_size, nb_layer, nb_classes):\n",
    "        super(LSTMNet,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nb_layer = nb_layer\n",
    "        self.nb_classes = nb_classes\n",
    "        self.lstm = nn.LSTM(in_size,hidden_size,nb_layer,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,nb_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # initial states\n",
    "        h0 = torch.zeros(self.nb_layer, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.nb_layer, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out,_ = self.lstm(x, (h0,c0))\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMNet(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.4039 (7.15 s)\n",
      "Epoch [1/2], Step [200/600], Loss: 0.3278 (13.67 s)\n",
      "Epoch [1/2], Step [300/600], Loss: 0.1684 (19.98 s)\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1691 (26.50 s)\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1562 (32.87 s)\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1348 (39.66 s)\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1532 (46.39 s)\n",
      "Epoch [2/2], Step [200/600], Loss: 0.1384 (53.07 s)\n",
      "Epoch [2/2], Step [300/600], Loss: 0.2222 (59.91 s)\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1333 (66.89 s)\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1669 (73.85 s)\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1843 (81.18 s)\n",
      "Test Accuracy: 97.36%\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "# training\n",
    "total_step = len(train_loader)\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(img,lab) in enumerate(train_loader):\n",
    "        img = img.reshape(-1,sequence_length,input_size).to(device)\n",
    "        lab = lab.to(device)\n",
    "\n",
    "        outputs = model(img)\n",
    "        loss = loss_fn(outputs,lab)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({:.2f} s)'\n",
    "            .format(epoch+1, num_epochs, i+1, total_step,\n",
    "            loss.item(), time.time()-start))\n",
    "\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, lab in test_loader:\n",
    "        img = img.reshape(-1,sequence_length,input_size).to(device)\n",
    "        lab = lab.to(device)\n",
    "        outputs = model(img)\n",
    "        _, pred = torch.max(outputs.data,1)\n",
    "        total += lab.size(0)\n",
    "        correct += (pred == lab).sum().item()\n",
    "\n",
    "    print('Test Accuracy: {}%'.format(100. * correct / total) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BiLSTM__\n",
    "\n",
    "On passe l'option \"bidirectional\" à \"True\" dans nn.LSTM, et on adapte les dimensions des tenseurs dans le réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005 # for BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define BiLSTM model\n",
    "class BiLSTMNet(nn.Module):\n",
    "    def __init__(self,in_size,hidden_size, nb_layer, nb_classes):\n",
    "        super(BiLSTMNet,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nb_layer = nb_layer\n",
    "        self.nb_classes = nb_classes\n",
    "        self.lstm = nn.LSTM(in_size,hidden_size,nb_layer,batch_first=True,bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2,nb_classes)  # 2 for bidirection\n",
    "\n",
    "    def forward(self,x):\n",
    "        # initial states\n",
    "        h0 = torch.zeros(self.nb_layer*2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.nb_layer*2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out,_ = self.lstm(x, (h0,c0))\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTMNet(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.3197 (10.08 s)\n",
      "Epoch [1/2], Step [200/600], Loss: 0.2139 (20.82 s)\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2383 (35.91 s)\n",
      "Epoch [1/2], Step [400/600], Loss: 0.0824 (47.07 s)\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1029 (58.03 s)\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1718 (68.81 s)\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1078 (80.99 s)\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0576 (92.79 s)\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0547 (104.55 s)\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1096 (116.36 s)\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1127 (128.24 s)\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1249 (141.05 s)\n",
      "Test Accuracy: 96.85%\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "total_step = len(train_loader)\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(img,lab) in enumerate(train_loader):\n",
    "        img = img.reshape(-1,sequence_length,input_size).to(device)\n",
    "        lab = lab.to(device)\n",
    "\n",
    "        outputs = model(img)\n",
    "        loss = loss_fn(outputs,lab)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} ({:.2f} s)'\n",
    "            .format(epoch+1, num_epochs, i+1, total_step,\n",
    "            loss.item(), time.time()-start))\n",
    "\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, lab in test_loader:\n",
    "        img = img.reshape(-1,sequence_length,input_size).to(device)\n",
    "        lab = lab.to(device)\n",
    "        outputs = model(img)\n",
    "        _, pred = torch.max(outputs.data,1)\n",
    "        total += lab.size(0)\n",
    "        correct += (pred == lab).sum().item()\n",
    "\n",
    "    print('Test Accuracy: {}%'.format(100. * correct / total) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
